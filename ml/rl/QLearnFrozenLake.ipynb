{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Q-Learning\n",
    "\n",
    "* Author: Johannes Maucher\n",
    "* Last update: 16.09.2021\n",
    "\n",
    "\n",
    "This notebook demonstrates Q-Learning by an example, where an agent has to navigate from a start-state to a goal-state. The [Frozen Lake Environment](https://gym.openai.com/envs/FrozenLake-v0/)is provided by [Open AI gym](https://gym.openai.com)\n",
    "\n",
    "\n",
    "## Environment\n",
    "\n",
    "**Description:** (from [Frozen Lake](https://gym.openai.com/envs/FrozenLake-v0/))\n",
    "\n",
    "*Winter is here. You and your friends were tossing around a frisbee at the park when you made a wild throw that left the frisbee out in the middle of the lake. The water is mostly frozen, but there are a few holes where the ice has melted. If you step into one of those holes, you'll fall into the freezing water. At this time, there's an international frisbee shortage, so it's absolutely imperative that you navigate across the lake and retrieve the disc. However, the ice is slippery, so you won't always move in the direction you intend.*\n",
    "\n",
    "As depicted below the environment consists of 16 states, indexed by 0 to 15 from the upper right to the lower left corner. There are 4 different types of states:\n",
    "\n",
    "* S: Start (safe)\n",
    "* F: Frozen (safe)\n",
    "* H: Hole (Game lost)\n",
    "* G: Goal (Game won)\n",
    "\n",
    "The task is to find a policy for the agent to navigate efficiently from the Start (S) to the Goal (G) state. \n",
    "\n",
    "![Frozen Lake pic](https://maucher.home.hdm-stuttgart.de/Pics/FrozenWorld.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actions\n",
    "\n",
    "The agent can move left (0), down (1), right (2) or up (3). If the agent moves to a wall it remains in the current state.\n",
    "\n",
    "## Transition- and Reward-Model\n",
    "In states `H` and `G` the game is over. In states `S` and `F` the transition modell is defined by:\n",
    "* the probability that the agent actually moves in the direction, defined by the selected action is $1/3$.\n",
    "* the probability that the agent moves to the field left-perpendicular to the direction given by the selected action is $1/3$.\n",
    "* the probability that the agent moves to the field right-perpendicular to the direction given by the selected action is $1/3$.\n",
    "\n",
    "The reward for turning into state `G` is 1. Turning in any other state yields no reward (r=0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some functions of gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "np.random.seed(123456)\n",
    "np.set_printoptions(precision=4,suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('FrozenLake-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n"
     ]
    }
   ],
   "source": [
    "env.render(mode=\"human\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[b'S', b'F', b'F', b'F'],\n",
       "       [b'F', b'H', b'F', b'H'],\n",
       "       [b'F', b'F', b'F', b'H'],\n",
       "       [b'H', b'F', b'F', b'G']], dtype='|S1')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.env.desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.env.reward_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(16)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete Environment-, Action-, Transition- and reward-model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {0: [(0.3333333333333333, 0, 0.0, False),\n",
       "   (0.3333333333333333, 0, 0.0, False),\n",
       "   (0.3333333333333333, 4, 0.0, False)],\n",
       "  1: [(0.3333333333333333, 0, 0.0, False),\n",
       "   (0.3333333333333333, 4, 0.0, False),\n",
       "   (0.3333333333333333, 1, 0.0, False)],\n",
       "  2: [(0.3333333333333333, 4, 0.0, False),\n",
       "   (0.3333333333333333, 1, 0.0, False),\n",
       "   (0.3333333333333333, 0, 0.0, False)],\n",
       "  3: [(0.3333333333333333, 1, 0.0, False),\n",
       "   (0.3333333333333333, 0, 0.0, False),\n",
       "   (0.3333333333333333, 0, 0.0, False)]},\n",
       " 1: {0: [(0.3333333333333333, 1, 0.0, False),\n",
       "   (0.3333333333333333, 0, 0.0, False),\n",
       "   (0.3333333333333333, 5, 0.0, True)],\n",
       "  1: [(0.3333333333333333, 0, 0.0, False),\n",
       "   (0.3333333333333333, 5, 0.0, True),\n",
       "   (0.3333333333333333, 2, 0.0, False)],\n",
       "  2: [(0.3333333333333333, 5, 0.0, True),\n",
       "   (0.3333333333333333, 2, 0.0, False),\n",
       "   (0.3333333333333333, 1, 0.0, False)],\n",
       "  3: [(0.3333333333333333, 2, 0.0, False),\n",
       "   (0.3333333333333333, 1, 0.0, False),\n",
       "   (0.3333333333333333, 0, 0.0, False)]},\n",
       " 2: {0: [(0.3333333333333333, 2, 0.0, False),\n",
       "   (0.3333333333333333, 1, 0.0, False),\n",
       "   (0.3333333333333333, 6, 0.0, False)],\n",
       "  1: [(0.3333333333333333, 1, 0.0, False),\n",
       "   (0.3333333333333333, 6, 0.0, False),\n",
       "   (0.3333333333333333, 3, 0.0, False)],\n",
       "  2: [(0.3333333333333333, 6, 0.0, False),\n",
       "   (0.3333333333333333, 3, 0.0, False),\n",
       "   (0.3333333333333333, 2, 0.0, False)],\n",
       "  3: [(0.3333333333333333, 3, 0.0, False),\n",
       "   (0.3333333333333333, 2, 0.0, False),\n",
       "   (0.3333333333333333, 1, 0.0, False)]},\n",
       " 3: {0: [(0.3333333333333333, 3, 0.0, False),\n",
       "   (0.3333333333333333, 2, 0.0, False),\n",
       "   (0.3333333333333333, 7, 0.0, True)],\n",
       "  1: [(0.3333333333333333, 2, 0.0, False),\n",
       "   (0.3333333333333333, 7, 0.0, True),\n",
       "   (0.3333333333333333, 3, 0.0, False)],\n",
       "  2: [(0.3333333333333333, 7, 0.0, True),\n",
       "   (0.3333333333333333, 3, 0.0, False),\n",
       "   (0.3333333333333333, 3, 0.0, False)],\n",
       "  3: [(0.3333333333333333, 3, 0.0, False),\n",
       "   (0.3333333333333333, 3, 0.0, False),\n",
       "   (0.3333333333333333, 2, 0.0, False)]},\n",
       " 4: {0: [(0.3333333333333333, 0, 0.0, False),\n",
       "   (0.3333333333333333, 4, 0.0, False),\n",
       "   (0.3333333333333333, 8, 0.0, False)],\n",
       "  1: [(0.3333333333333333, 4, 0.0, False),\n",
       "   (0.3333333333333333, 8, 0.0, False),\n",
       "   (0.3333333333333333, 5, 0.0, True)],\n",
       "  2: [(0.3333333333333333, 8, 0.0, False),\n",
       "   (0.3333333333333333, 5, 0.0, True),\n",
       "   (0.3333333333333333, 0, 0.0, False)],\n",
       "  3: [(0.3333333333333333, 5, 0.0, True),\n",
       "   (0.3333333333333333, 0, 0.0, False),\n",
       "   (0.3333333333333333, 4, 0.0, False)]},\n",
       " 5: {0: [(1.0, 5, 0, True)],\n",
       "  1: [(1.0, 5, 0, True)],\n",
       "  2: [(1.0, 5, 0, True)],\n",
       "  3: [(1.0, 5, 0, True)]},\n",
       " 6: {0: [(0.3333333333333333, 2, 0.0, False),\n",
       "   (0.3333333333333333, 5, 0.0, True),\n",
       "   (0.3333333333333333, 10, 0.0, False)],\n",
       "  1: [(0.3333333333333333, 5, 0.0, True),\n",
       "   (0.3333333333333333, 10, 0.0, False),\n",
       "   (0.3333333333333333, 7, 0.0, True)],\n",
       "  2: [(0.3333333333333333, 10, 0.0, False),\n",
       "   (0.3333333333333333, 7, 0.0, True),\n",
       "   (0.3333333333333333, 2, 0.0, False)],\n",
       "  3: [(0.3333333333333333, 7, 0.0, True),\n",
       "   (0.3333333333333333, 2, 0.0, False),\n",
       "   (0.3333333333333333, 5, 0.0, True)]},\n",
       " 7: {0: [(1.0, 7, 0, True)],\n",
       "  1: [(1.0, 7, 0, True)],\n",
       "  2: [(1.0, 7, 0, True)],\n",
       "  3: [(1.0, 7, 0, True)]},\n",
       " 8: {0: [(0.3333333333333333, 4, 0.0, False),\n",
       "   (0.3333333333333333, 8, 0.0, False),\n",
       "   (0.3333333333333333, 12, 0.0, True)],\n",
       "  1: [(0.3333333333333333, 8, 0.0, False),\n",
       "   (0.3333333333333333, 12, 0.0, True),\n",
       "   (0.3333333333333333, 9, 0.0, False)],\n",
       "  2: [(0.3333333333333333, 12, 0.0, True),\n",
       "   (0.3333333333333333, 9, 0.0, False),\n",
       "   (0.3333333333333333, 4, 0.0, False)],\n",
       "  3: [(0.3333333333333333, 9, 0.0, False),\n",
       "   (0.3333333333333333, 4, 0.0, False),\n",
       "   (0.3333333333333333, 8, 0.0, False)]},\n",
       " 9: {0: [(0.3333333333333333, 5, 0.0, True),\n",
       "   (0.3333333333333333, 8, 0.0, False),\n",
       "   (0.3333333333333333, 13, 0.0, False)],\n",
       "  1: [(0.3333333333333333, 8, 0.0, False),\n",
       "   (0.3333333333333333, 13, 0.0, False),\n",
       "   (0.3333333333333333, 10, 0.0, False)],\n",
       "  2: [(0.3333333333333333, 13, 0.0, False),\n",
       "   (0.3333333333333333, 10, 0.0, False),\n",
       "   (0.3333333333333333, 5, 0.0, True)],\n",
       "  3: [(0.3333333333333333, 10, 0.0, False),\n",
       "   (0.3333333333333333, 5, 0.0, True),\n",
       "   (0.3333333333333333, 8, 0.0, False)]},\n",
       " 10: {0: [(0.3333333333333333, 6, 0.0, False),\n",
       "   (0.3333333333333333, 9, 0.0, False),\n",
       "   (0.3333333333333333, 14, 0.0, False)],\n",
       "  1: [(0.3333333333333333, 9, 0.0, False),\n",
       "   (0.3333333333333333, 14, 0.0, False),\n",
       "   (0.3333333333333333, 11, 0.0, True)],\n",
       "  2: [(0.3333333333333333, 14, 0.0, False),\n",
       "   (0.3333333333333333, 11, 0.0, True),\n",
       "   (0.3333333333333333, 6, 0.0, False)],\n",
       "  3: [(0.3333333333333333, 11, 0.0, True),\n",
       "   (0.3333333333333333, 6, 0.0, False),\n",
       "   (0.3333333333333333, 9, 0.0, False)]},\n",
       " 11: {0: [(1.0, 11, 0, True)],\n",
       "  1: [(1.0, 11, 0, True)],\n",
       "  2: [(1.0, 11, 0, True)],\n",
       "  3: [(1.0, 11, 0, True)]},\n",
       " 12: {0: [(1.0, 12, 0, True)],\n",
       "  1: [(1.0, 12, 0, True)],\n",
       "  2: [(1.0, 12, 0, True)],\n",
       "  3: [(1.0, 12, 0, True)]},\n",
       " 13: {0: [(0.3333333333333333, 9, 0.0, False),\n",
       "   (0.3333333333333333, 12, 0.0, True),\n",
       "   (0.3333333333333333, 13, 0.0, False)],\n",
       "  1: [(0.3333333333333333, 12, 0.0, True),\n",
       "   (0.3333333333333333, 13, 0.0, False),\n",
       "   (0.3333333333333333, 14, 0.0, False)],\n",
       "  2: [(0.3333333333333333, 13, 0.0, False),\n",
       "   (0.3333333333333333, 14, 0.0, False),\n",
       "   (0.3333333333333333, 9, 0.0, False)],\n",
       "  3: [(0.3333333333333333, 14, 0.0, False),\n",
       "   (0.3333333333333333, 9, 0.0, False),\n",
       "   (0.3333333333333333, 12, 0.0, True)]},\n",
       " 14: {0: [(0.3333333333333333, 10, 0.0, False),\n",
       "   (0.3333333333333333, 13, 0.0, False),\n",
       "   (0.3333333333333333, 14, 0.0, False)],\n",
       "  1: [(0.3333333333333333, 13, 0.0, False),\n",
       "   (0.3333333333333333, 14, 0.0, False),\n",
       "   (0.3333333333333333, 15, 1.0, True)],\n",
       "  2: [(0.3333333333333333, 14, 0.0, False),\n",
       "   (0.3333333333333333, 15, 1.0, True),\n",
       "   (0.3333333333333333, 10, 0.0, False)],\n",
       "  3: [(0.3333333333333333, 15, 1.0, True),\n",
       "   (0.3333333333333333, 10, 0.0, False),\n",
       "   (0.3333333333333333, 13, 0.0, False)]},\n",
       " 15: {0: [(1.0, 15, 0, True)],\n",
       "  1: [(1.0, 15, 0, True)],\n",
       "  2: [(1.0, 15, 0, True)],\n",
       "  3: [(1.0, 15, 0, True)]}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.env.P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3333333333333333, 4, 0.0, False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start=0\n",
    "targetDirection=1 # 0:left, 1:down, 2:right, 3:up\n",
    "drift=1           # 0:drift to right, 1 no drift, 2: drift to left\n",
    "env.env.P[start][targetDirection][drift]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability for this drift: 0.333\n",
      "New state:  4\n",
      "Reward: 0.00\n",
      "Game over?: False\n"
     ]
    }
   ],
   "source": [
    "print(\"Probability for this drift: %1.3f\"%env.env.P[start][targetDirection][drift][0])\n",
    "print(\"New state: %2d\"%env.env.P[start][targetDirection][drift][1])\n",
    "print(\"Reward: %2.2f\"%env.env.P[start][targetDirection][drift][2])\n",
    "print(\"Game over?: %s\"%env.env.P[start][targetDirection][drift][3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interaction with gym environment\n",
    "Execute action and obtain new state and reward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old state:  0\n",
      "New state:  0 \t Reward:  0.0 \t Game Over?:  False\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "action=0\n",
    "print(\"Old state: \",env.env.s)\n",
    "s1,r,d,_=env.step(action) # s1 is new state, r is reward and d is True if game is over\n",
    "print(\"New state: \",s1, \"\\t Reward: \",r, \"\\t Game Over?: \",d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "Old state:  0\n",
      "Intended Action:  1\n",
      "New state:  0 \t Reward:  0.0 \t Game Over?:  False\n",
      "----------\n",
      "Old state:  0\n",
      "Intended Action:  2\n",
      "New state:  1 \t Reward:  0.0 \t Game Over?:  False\n",
      "----------\n",
      "Old state:  1\n",
      "Intended Action:  2\n",
      "New state:  2 \t Reward:  0.0 \t Game Over?:  False\n",
      "----------\n",
      "Old state:  2\n",
      "Intended Action:  1\n",
      "New state:  3 \t Reward:  0.0 \t Game Over?:  False\n",
      "----------\n",
      "Old state:  3\n",
      "Intended Action:  0\n",
      "New state:  7 \t Reward:  0.0 \t Game Over?:  True\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "d=False\n",
    "while not d:\n",
    "    print(\"-\"*10)\n",
    "    print(\"Old state: \",env.env.s)\n",
    "    action=np.random.randint(4)\n",
    "    print(\"Intended Action: \",action)\n",
    "    s1,r,d,_=env.step(action) # s1 is new state, r is reward and d is True if game is over\n",
    "    print(\"New state: \",s1, \"\\t Reward: \",r, \"\\t Game Over?: \",d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Q-Learning in Table Representation\n",
    "\n",
    "In this section Q-learning, as defined in the pseudo code below is implemented:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Q Learning Pseudo Code Image](https://maucher.home.hdm-stuttgart.de/Pics/QlearningPseudoCode.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialization and hyperparameter setting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize table with all zeros\n",
    "Q = np.zeros([env.observation_space.n,env.action_space.n])\n",
    "# Set learning parameters\n",
    "lr = .9   # parameter \\alpha  \n",
    "y = .95 #discount \\nu\n",
    "num_episodes = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Table of Q-values: \n",
      " [[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Initial Table of Q-values: \\n\",Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the array above each row belongs to a state and each column belongs to an action. The entry in row i, column j is the $Q(s,a)$-value for the j.th action in the i.th state. Initially all these values are zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9742, 0.7191, 0.1848, 0.6193]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randn(1,env.action_space.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code-cell below Q-learning is implemented. Note that the action-selection, in particular the Explore/Exploit-Trade-Off, is implemented such that with an increasing number of episodes the random contribution to action-selection decreases: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create lists to contain total rewards and steps per episode\n",
    "rList = []\n",
    "for i in range(num_episodes):\n",
    "    #Reset environment and get first new observation\n",
    "    s = env.reset()\n",
    "    rAll = 0\n",
    "    d = False\n",
    "    j = 0\n",
    "    #The Q-Table learning algorithm\n",
    "    while j < 99:\n",
    "        j+=1\n",
    "        #Choose an action by greedily (with noise) picking from Q table\n",
    "        options=Q[s,:] + np.random.randn(1,env.action_space.n)*(1./(i+1))\n",
    "        a = np.argmax(options)\n",
    "        #Get new state and reward from environment\n",
    "        s1,r,d,_ = env.step(a)\n",
    "        #print(s,a,s1)\n",
    "        #Update Q-Table with new knowledge\n",
    "        Q[s,a] = Q[s,a] + lr*(r + y*np.max(Q[s1,:]) - Q[s,a])\n",
    "        rAll += r\n",
    "        s = s1\n",
    "        if d == True:\n",
    "            break\n",
    "    #jList.append(j)\n",
    "    rList.append(rAll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score over time: 0.562\n"
     ]
    }
   ],
   "source": [
    "print(\"Score over time: \" +  str(sum(rList)/num_episodes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learned Policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final $Q(s_t,a_t)$-values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1599, 0.0009, 0.0009, 0.0011],\n",
       "       [0.0001, 0.0003, 0.0001, 0.0882],\n",
       "       [0.1588, 0.0014, 0.0003, 0.0011],\n",
       "       [0.    , 0.0011, 0.0011, 0.0462],\n",
       "       [0.2731, 0.0001, 0.0001, 0.0001],\n",
       "       [0.    , 0.    , 0.    , 0.    ],\n",
       "       [0.0017, 0.0001, 0.0001, 0.    ],\n",
       "       [0.    , 0.    , 0.    , 0.    ],\n",
       "       [0.0009, 0.0006, 0.    , 0.6112],\n",
       "       [0.    , 0.1364, 0.    , 0.0001],\n",
       "       [0.0228, 0.0006, 0.0008, 0.    ],\n",
       "       [0.    , 0.    , 0.    , 0.    ],\n",
       "       [0.    , 0.    , 0.    , 0.    ],\n",
       "       [0.0042, 0.0006, 0.6018, 0.0013],\n",
       "       [0.    , 0.6709, 0.    , 0.    ],\n",
       "       [0.    , 0.    , 0.    , 0.    ]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each state (row in the array above) the action of the learned strategy is the positon with the maximal value in the corresponding row: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy=np.argmax(Q,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 3, 0, 3, 0, 0, 0, 0, 3, 1, 0, 0, 0, 2, 1, 0])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best action in state  0 is  0\n",
      "Best action in state  3 is  3\n",
      "Best action in state  0 is  0\n",
      "Best action in state  3 is  3\n",
      "Best action in state  0 is  0\n",
      "Best action in state  0 is  0\n",
      "Best action in state  0 is  0\n",
      "Best action in state  0 is  0\n",
      "Best action in state  3 is  3\n",
      "Best action in state  1 is  3\n",
      "Best action in state  0 is  0\n",
      "Best action in state  0 is  0\n",
      "Best action in state  0 is  0\n",
      "Best action in state  2 is  0\n",
      "Best action in state  1 is  3\n",
      "Best action in state  0 is  0\n"
     ]
    }
   ],
   "source": [
    "actionList=[\"Left\",\"Down\",\"Right\",\"Up\"]\n",
    "for state in strategy:\n",
    "    print(\"Best action in state %2d is %2s\"%(state,strategy[state]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "Old state:  0\n",
      "Intended Action:  0\n",
      "New state:  0 \t Reward:  0.0 \t Game Over?:  False\n",
      "----------\n",
      "Old state:  0\n",
      "Intended Action:  0\n",
      "New state:  4 \t Reward:  0.0 \t Game Over?:  False\n",
      "----------\n",
      "Old state:  4\n",
      "Intended Action:  0\n",
      "New state:  0 \t Reward:  0.0 \t Game Over?:  False\n",
      "----------\n",
      "Old state:  0\n",
      "Intended Action:  0\n",
      "New state:  4 \t Reward:  0.0 \t Game Over?:  False\n",
      "----------\n",
      "Old state:  4\n",
      "Intended Action:  0\n",
      "New state:  0 \t Reward:  0.0 \t Game Over?:  False\n",
      "----------\n",
      "Old state:  0\n",
      "Intended Action:  0\n",
      "New state:  0 \t Reward:  0.0 \t Game Over?:  False\n",
      "----------\n",
      "Old state:  0\n",
      "Intended Action:  0\n",
      "New state:  4 \t Reward:  0.0 \t Game Over?:  False\n",
      "----------\n",
      "Old state:  4\n",
      "Intended Action:  0\n",
      "New state:  4 \t Reward:  0.0 \t Game Over?:  False\n",
      "----------\n",
      "Old state:  4\n",
      "Intended Action:  0\n",
      "New state:  0 \t Reward:  0.0 \t Game Over?:  False\n",
      "----------\n",
      "Old state:  0\n",
      "Intended Action:  0\n",
      "New state:  0 \t Reward:  0.0 \t Game Over?:  False\n",
      "----------\n",
      "Old state:  0\n",
      "Intended Action:  0\n",
      "New state:  0 \t Reward:  0.0 \t Game Over?:  False\n",
      "----------\n",
      "Old state:  0\n",
      "Intended Action:  0\n",
      "New state:  0 \t Reward:  0.0 \t Game Over?:  False\n",
      "----------\n",
      "Old state:  0\n",
      "Intended Action:  0\n",
      "New state:  4 \t Reward:  0.0 \t Game Over?:  False\n",
      "----------\n",
      "Old state:  4\n",
      "Intended Action:  0\n",
      "New state:  8 \t Reward:  0.0 \t Game Over?:  False\n",
      "----------\n",
      "Old state:  8\n",
      "Intended Action:  3\n",
      "New state:  4 \t Reward:  0.0 \t Game Over?:  False\n",
      "----------\n",
      "Old state:  4\n",
      "Intended Action:  0\n",
      "New state:  8 \t Reward:  0.0 \t Game Over?:  False\n",
      "----------\n",
      "Old state:  8\n",
      "Intended Action:  3\n",
      "New state:  8 \t Reward:  0.0 \t Game Over?:  False\n",
      "----------\n",
      "Old state:  8\n",
      "Intended Action:  3\n",
      "New state:  8 \t Reward:  0.0 \t Game Over?:  False\n",
      "----------\n",
      "Old state:  8\n",
      "Intended Action:  3\n",
      "New state:  8 \t Reward:  0.0 \t Game Over?:  False\n",
      "----------\n",
      "Old state:  8\n",
      "Intended Action:  3\n",
      "New state:  4 \t Reward:  0.0 \t Game Over?:  False\n",
      "----------\n",
      "Old state:  4\n",
      "Intended Action:  0\n",
      "New state:  0 \t Reward:  0.0 \t Game Over?:  False\n",
      "----------\n",
      "Old state:  0\n",
      "Intended Action:  0\n",
      "New state:  0 \t Reward:  0.0 \t Game Over?:  False\n",
      "----------\n",
      "Old state:  0\n",
      "Intended Action:  0\n",
      "New state:  0 \t Reward:  0.0 \t Game Over?:  False\n",
      "----------\n",
      "Old state:  0\n",
      "Intended Action:  0\n",
      "New state:  4 \t Reward:  0.0 \t Game Over?:  False\n",
      "----------\n",
      "Old state:  4\n",
      "Intended Action:  0\n",
      "New state:  4 \t Reward:  0.0 \t Game Over?:  False\n",
      "----------\n",
      "Old state:  4\n",
      "Intended Action:  0\n",
      "New state:  0 \t Reward:  0.0 \t Game Over?:  False\n",
      "----------\n",
      "Old state:  0\n",
      "Intended Action:  0\n",
      "New state:  0 \t Reward:  0.0 \t Game Over?:  False\n",
      "----------\n",
      "Old state:  0\n",
      "Intended Action:  0\n",
      "New state:  4 \t Reward:  0.0 \t Game Over?:  False\n",
      "----------\n",
      "Old state:  4\n",
      "Intended Action:  0\n",
      "New state:  8 \t Reward:  0.0 \t Game Over?:  False\n",
      "----------\n",
      "Old state:  8\n",
      "Intended Action:  3\n",
      "New state:  4 \t Reward:  0.0 \t Game Over?:  False\n",
      "----------\n",
      "Old state:  4\n",
      "Intended Action:  0\n",
      "New state:  8 \t Reward:  0.0 \t Game Over?:  False\n",
      "----------\n",
      "Old state:  8\n",
      "Intended Action:  3\n",
      "New state:  4 \t Reward:  0.0 \t Game Over?:  False\n",
      "----------\n",
      "Old state:  4\n",
      "Intended Action:  0\n",
      "New state:  0 \t Reward:  0.0 \t Game Over?:  False\n",
      "----------\n",
      "Old state:  0\n",
      "Intended Action:  0\n",
      "New state:  0 \t Reward:  0.0 \t Game Over?:  False\n",
      "----------\n",
      "Old state:  0\n",
      "Intended Action:  0\n",
      "New state:  4 \t Reward:  0.0 \t Game Over?:  False\n",
      "----------\n",
      "Old state:  4\n",
      "Intended Action:  0\n",
      "New state:  0 \t Reward:  0.0 \t Game Over?:  False\n",
      "----------\n",
      "Old state:  0\n",
      "Intended Action:  0\n",
      "New state:  4 \t Reward:  0.0 \t Game Over?:  False\n",
      "----------\n",
      "Old state:  4\n",
      "Intended Action:  0\n",
      "New state:  4 \t Reward:  0.0 \t Game Over?:  False\n",
      "----------\n",
      "Old state:  4\n",
      "Intended Action:  0\n",
      "New state:  4 \t Reward:  0.0 \t Game Over?:  False\n",
      "----------\n",
      "Old state:  4\n",
      "Intended Action:  0\n",
      "New state:  4 \t Reward:  0.0 \t Game Over?:  False\n",
      "----------\n",
      "Old state:  4\n",
      "Intended Action:  0\n",
      "New state:  4 \t Reward:  0.0 \t Game Over?:  False\n",
      "----------\n",
      "Old state:  4\n",
      "Intended Action:  0\n",
      "New state:  0 \t Reward:  0.0 \t Game Over?:  False\n",
      "----------\n",
      "Old state:  0\n",
      "Intended Action:  0\n",
      "New state:  0 \t Reward:  0.0 \t Game Over?:  False\n",
      "----------\n",
      "Old state:  0\n",
      "Intended Action:  0\n",
      "New state:  0 \t Reward:  0.0 \t Game Over?:  False\n",
      "----------\n",
      "Old state:  0\n",
      "Intended Action:  0\n",
      "New state:  0 \t Reward:  0.0 \t Game Over?:  False\n",
      "----------\n",
      "Old state:  0\n",
      "Intended Action:  0\n",
      "New state:  0 \t Reward:  0.0 \t Game Over?:  False\n",
      "----------\n",
      "Old state:  0\n",
      "Intended Action:  0\n",
      "New state:  4 \t Reward:  0.0 \t Game Over?:  False\n",
      "----------\n",
      "Old state:  4\n",
      "Intended Action:  0\n",
      "New state:  4 \t Reward:  0.0 \t Game Over?:  False\n",
      "----------\n",
      "Old state:  4\n",
      "Intended Action:  0\n",
      "New state:  4 \t Reward:  0.0 \t Game Over?:  False\n",
      "----------\n",
      "Old state:  4\n",
      "Intended Action:  0\n",
      "New state:  4 \t Reward:  0.0 \t Game Over?:  False\n",
      "----------\n",
      "Old state:  4\n",
      "Intended Action:  0\n",
      "New state:  4 \t Reward:  0.0 \t Game Over?:  False\n",
      "----------\n",
      "Old state:  4\n",
      "Intended Action:  0\n",
      "New state:  0 \t Reward:  0.0 \t Game Over?:  False\n",
      "----------\n",
      "Old state:  0\n",
      "Intended Action:  0\n",
      "New state:  4 \t Reward:  0.0 \t Game Over?:  False\n",
      "----------\n",
      "Old state:  4\n",
      "Intended Action:  0\n",
      "New state:  0 \t Reward:  0.0 \t Game Over?:  False\n",
      "----------\n",
      "Old state:  0\n",
      "Intended Action:  0\n",
      "New state:  0 \t Reward:  0.0 \t Game Over?:  False\n",
      "----------\n",
      "Old state:  0\n",
      "Intended Action:  0\n",
      "New state:  0 \t Reward:  0.0 \t Game Over?:  False\n",
      "----------\n",
      "Old state:  0\n",
      "Intended Action:  0\n",
      "New state:  0 \t Reward:  0.0 \t Game Over?:  False\n",
      "----------\n",
      "Old state:  0\n",
      "Intended Action:  0\n",
      "New state:  0 \t Reward:  0.0 \t Game Over?:  False\n",
      "----------\n",
      "Old state:  0\n",
      "Intended Action:  0\n",
      "New state:  4 \t Reward:  0.0 \t Game Over?:  False\n",
      "----------\n",
      "Old state:  4\n",
      "Intended Action:  0\n",
      "New state:  8 \t Reward:  0.0 \t Game Over?:  False\n",
      "----------\n",
      "Old state:  8\n",
      "Intended Action:  3\n",
      "New state:  8 \t Reward:  0.0 \t Game Over?:  False\n",
      "----------\n",
      "Old state:  8\n",
      "Intended Action:  3\n",
      "New state:  9 \t Reward:  0.0 \t Game Over?:  False\n",
      "----------\n",
      "Old state:  9\n",
      "Intended Action:  1\n",
      "New state:  13 \t Reward:  0.0 \t Game Over?:  False\n",
      "----------\n",
      "Old state:  13\n",
      "Intended Action:  2\n",
      "New state:  14 \t Reward:  0.0 \t Game Over?:  False\n",
      "----------\n",
      "Old state:  14\n",
      "Intended Action:  1\n",
      "New state:  14 \t Reward:  0.0 \t Game Over?:  False\n",
      "----------\n",
      "Old state:  14\n",
      "Intended Action:  1\n",
      "New state:  14 \t Reward:  0.0 \t Game Over?:  False\n",
      "----------\n",
      "Old state:  14\n",
      "Intended Action:  1\n",
      "New state:  13 \t Reward:  0.0 \t Game Over?:  False\n",
      "----------\n",
      "Old state:  13\n",
      "Intended Action:  2\n",
      "New state:  14 \t Reward:  0.0 \t Game Over?:  False\n",
      "----------\n",
      "Old state:  14\n",
      "Intended Action:  1\n",
      "New state:  13 \t Reward:  0.0 \t Game Over?:  False\n",
      "----------\n",
      "Old state:  13\n",
      "Intended Action:  2\n",
      "New state:  9 \t Reward:  0.0 \t Game Over?:  False\n",
      "----------\n",
      "Old state:  9\n",
      "Intended Action:  1\n",
      "New state:  10 \t Reward:  0.0 \t Game Over?:  False\n",
      "----------\n",
      "Old state:  10\n",
      "Intended Action:  0\n",
      "New state:  9 \t Reward:  0.0 \t Game Over?:  False\n",
      "----------\n",
      "Old state:  9\n",
      "Intended Action:  1\n",
      "New state:  13 \t Reward:  0.0 \t Game Over?:  False\n",
      "----------\n",
      "Old state:  13\n",
      "Intended Action:  2\n",
      "New state:  9 \t Reward:  0.0 \t Game Over?:  False\n",
      "----------\n",
      "Old state:  9\n",
      "Intended Action:  1\n",
      "New state:  13 \t Reward:  0.0 \t Game Over?:  False\n",
      "----------\n",
      "Old state:  13\n",
      "Intended Action:  2\n",
      "New state:  14 \t Reward:  0.0 \t Game Over?:  False\n",
      "----------\n",
      "Old state:  14\n",
      "Intended Action:  1\n",
      "New state:  15 \t Reward:  1.0 \t Game Over?:  True\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "d=False\n",
    "while not d:\n",
    "    print(\"-\"*10)\n",
    "    print(\"Old state: \",env.env.s)\n",
    "    #action=np.random.randint(4)\n",
    "    action=strategy[env.env.s]\n",
    "    print(\"Intended Action: \",action)\n",
    "    s1,r,d,_=env.step(action) # s1 is new state, r is reward and d is True if game is over\n",
    "    print(\"New state: \",s1, \"\\t Reward: \",r, \"\\t Game Over?: \",d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game terminated with:\n",
      "Final state:  15 \t Reward:  1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Game terminated with:\")\n",
    "print(\"Final state: \",s1, \"\\t Reward: \",r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import InputLayer, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(InputLayer(batch_input_shape=(1, 16)))\n",
    "model.add(Dense(50, activation='sigmoid',use_bias=False))\n",
    "model.add(Dense(4, activation='linear',use_bias=False))\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1 of 5000\n",
      "Episode 101 of 5000\n",
      "Episode 201 of 5000\n",
      "Episode 301 of 5000\n",
      "Episode 401 of 5000\n",
      "Episode 501 of 5000\n",
      "Episode 601 of 5000\n",
      "Episode 701 of 5000\n",
      "Episode 801 of 5000\n",
      "Episode 901 of 5000\n",
      "Episode 1001 of 5000\n",
      "Episode 1101 of 5000\n",
      "Episode 1201 of 5000\n",
      "Episode 1301 of 5000\n",
      "Episode 1401 of 5000\n",
      "Episode 1501 of 5000\n",
      "Episode 1601 of 5000\n",
      "Episode 1701 of 5000\n",
      "Episode 1801 of 5000\n",
      "Episode 1901 of 5000\n",
      "Episode 2001 of 5000\n",
      "Episode 2101 of 5000\n",
      "Episode 2201 of 5000\n",
      "Episode 2301 of 5000\n",
      "Episode 2401 of 5000\n",
      "Episode 2501 of 5000\n",
      "Episode 2601 of 5000\n",
      "Episode 2701 of 5000\n",
      "Episode 2801 of 5000\n",
      "Episode 2901 of 5000\n",
      "Episode 3001 of 5000\n",
      "Episode 3101 of 5000\n",
      "Episode 3201 of 5000\n",
      "Episode 3301 of 5000\n",
      "Episode 3401 of 5000\n",
      "Episode 3501 of 5000\n",
      "Episode 3601 of 5000\n",
      "Episode 3701 of 5000\n",
      "Episode 3801 of 5000\n",
      "Episode 3901 of 5000\n",
      "Episode 4001 of 5000\n",
      "Episode 4101 of 5000\n",
      "Episode 4201 of 5000\n",
      "Episode 4301 of 5000\n",
      "Episode 4401 of 5000\n",
      "Episode 4501 of 5000\n",
      "Episode 4601 of 5000\n",
      "Episode 4701 of 5000\n",
      "Episode 4801 of 5000\n",
      "Episode 4901 of 5000\n"
     ]
    }
   ],
   "source": [
    "# now execute the q learning\n",
    "y = 0.95\n",
    "eps = 0.5\n",
    "decay_factor = 0.999\n",
    "num_episodes=5000\n",
    "r_avg_list = []\n",
    "for i in range(num_episodes):\n",
    "    s = env.reset()\n",
    "    eps *= decay_factor\n",
    "    if i % 100 == 0:\n",
    "        print(\"Episode {} of {}\".format(i + 1, num_episodes))\n",
    "    done = False\n",
    "    r_sum = 0\n",
    "    while not done:\n",
    "        if np.random.random() < eps:\n",
    "            a = np.random.randint(0, 4)\n",
    "        else:\n",
    "            a = np.argmax(model.predict(np.identity(16)[s:s + 1]))\n",
    "        new_s, r, done, _ = env.step(a)\n",
    "        target = r + y * np.max(model.predict(np.identity(16)[new_s:new_s + 1]))\n",
    "        target_vec = model.predict(np.identity(16)[s:s + 1])[0]\n",
    "        target_vec[a] = target\n",
    "        model.fit(np.identity(16)[s:s + 1], target_vec.reshape(-1, 4), epochs=1, verbose=0)\n",
    "        s = new_s\n",
    "        r_sum += r\n",
    "    r_avg_list.append(r_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-31-454c3f8cd567>:1: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  winrate=[np.sum(r_avg_list[:count])/count for count in range(len(r_avg_list))]\n"
     ]
    }
   ],
   "source": [
    "winrate=[np.sum(r_avg_list[:count])/count for count in range(len(r_avg_list))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAyG0lEQVR4nO3deXwV1fn48c+TPSQhCUkIISGEJSwBBSFCwAUErYBWbF0KVlGrIlWq1dYW7ab9+m21P7XWfimKSgU3inVDxQVxQ1mDLIJhCXsgQNhCCGS95/fHTC43lxtyAyE3yTzv1+u+MnPmzL3nUDvPzDlnzhFjDEoppZwnKNAFUEopFRgaAJRSyqE0ACillENpAFBKKYfSAKCUUg4VEugCNERiYqLJyMgIdDGUUqpFWbFixX5jTJJ3eosKABkZGeTm5ga6GEop1aKIyHZf6doEpJRSDqUBQCmlHEoDgFJKOZQGAKWUcigNAEop5VAaAJRSyqH8CgAiMkpENohIvohM8XFcROQZ+/gaERngdTxYRFaKyPseae1EZL6IbLL/xp95dZRSSvmr3gAgIsHAVGA0kAWMF5Esr2yjgUz7MxGY5nX8XiDPK20KsMAYkwkssPeVUqrFcbkMc5bv5MDR8kAXpUH8eQIYBOQbY7YYYyqA2cBYrzxjgVnGsgSIE5EUABFJA64AXvBxzkx7eyZw9elVQSmlAmvW4m385s01DHz0U+Z/vzfQxfGbPwEgFdjpsV9gp/mb52ngN4DL65xkY0whgP23va8fF5GJIpIrIrlFRUV+FFcppZrWw+99D0BidDh3zMrlgTdWU1JWGeBS1c+fACA+0ryXEfOZR0SuBPYZY1Y0uGQ1X2LMdGNMtjEmOynppKkslFIqoDxXVVw0ZQR3X9KNN78tYNTTC1m8+UAAS1Y/f+YCKgA6eeynAbv9zHMtcJWIjAEigLYi8oox5kZgr4ikGGMK7eaifadbCaWUakqL8vfTK6Ut7aLC2H+0AoAHR/ciLCSIBy7vxcjeyfxqzmrGP7+EnskxBAUJd1zUhaKScsYPTqdtRGiAa2DxJwAsBzJFpAuwCxgH3OCVZy4wWURmA4OBYrtZ50H7g4gMB35tX/xrzrkZeMz+++4Z1UQppc4il8vwzGebeG/1bjYXlQJwTmosbcKCAWgbeeKiPiA9ng/uuZDHP1zPzMXWPGz3z1kNwIxvtpKREEXXpCgeuLwX7aLC2LCnhN2Hj1NSXsWV56QQFOSrUaXx1RsAjDFVIjIZ+BgIBmYYY9aJyCT7+LPAPGAMkA8cA27147cfA+aIyG3ADuC606uCUkqdPeVV1Xy+voi/z9/Ihr0ltY59t6vYvZ2V0rbWsTZhITwyti+X9+3A9gPH2LCnhAXr9xIeEszSrQdZuvUgn6zbyyNj+zD5tZXu8/79zVZKy6u48tyOTBrWjSfnbwAD94zMJCq8cSdwFs/2q+YuOzvb6HTQSqmm8sm6PUx8uXYX5lX9OjJuUCcGdo5n1qLtRIQGUXy8kp8P706wH3fuZZXVvLJkO+GhwbyRu5M1BSeCSIe2Eew5UubzvOk3DeQHfTqcVj1EZIUxJvukdA0ASinlW8aUD9zbvVPa8tPB6dyY07nRvr+q2sWMb7byzIJ8nv5Jfy7NSqaopJz/LN9BSmwkv3rDajb6w5VZ/OyCDEROr2lIA4BSSjXAgaPlDHz0UwC+fGA4nROimrwMpeVVbN1fSt/U2DP6nroCgM4FpJRSPizdehCw7r4DcfEHiAoPOeOL/6loAFBKKS+V1S7mrrJGu1/Ss/W+f6QBQCmlvLywcCsfrdsDQMe4yACX5uzRAKCUcqyyymoqq2vPUrNhTwmPf7QesIZeRoQGB6JoTUIDgFLKkUrLq+j1h4/I/N2HLMrf706//OmvAGgfE879l/UIVPGaROO+VaCUUs3EwdIKio9X0iXxRAfukbJKjldUU+UyXPDYZ+70G15YysDO8Rw6VuFOWzRlRJOWNxA0ACilWqVrpi1i6/5SJg3rxtHySkb1SeHxj9bXensXYP59F/Pyku3MsqdsAPj9Fb0JCW79DST6HoBSqtXZV1LGoP9dUG++RVNGuDt5F24qYk1BMWnxkQzv0Z7YNs1jwrbGUNd7APoEoJRq9o6UVTJn+U6uP79TvTNpLtt6kJteXArA/Zf1ICMxin99nk9STDgLN+3ngct7ktM1gZ4dYoj2mFvnoswkLspsvUM+fdEAoJRqlvaVlFFR5SItvg0frCnk0Q/ymLl4G/8cP4CYiBB+8txibhmawV3Du7tnz9y4t4Trn1vs/o67hncjJDiIq/p1BGBPcRlJMeF+zdnjBBoAlFLNTmW1y92EM7RbAovshVVcLrh22iKqXFbT9ROfbGTZtkM8cd25JEaF8+9vtrm/49kbB57Ujt8hNqJpKtBCaABQSjUb2w+UMvm1lbU6amsu/m3Cgpl370VMeXMNH661XtL6n7F9+N95eYx+eiEHSk+M4NnylzFNNqd+S6YBQCnVbLyzcneti//0mway6/Bx9pWUM2FIZ2IjQ/nXTwfw1re7CA4Srj4vlZyuCfzi9ZXuAJAaF6kXfz9pAFBKNamXl2ynf1och49X8Oj7eVyWlcw5abHsPnycv3+6EYA/XpnFsJ5JdEuKPul8EeGagWnu/czkGN6dfAFvrtjFeelxJESFNVldWjq/AoCIjAL+gbUi2AvGmMe8jot9fAzWimC3GGO+FZEI4Csg3P6t/xpj/mSf8zBwB1Bkf81Dxph5Z1wjpVSzdfhYBX94Z22tNO9VtgB+dmGXBn1veEgwNwxOP6OyOVG9bzqISDAwFRgNZAHjRSTLK9toINP+TASm2enlwAhjTD+gPzBKRHI8zvu7Maa//dGLv1KtiDGGI2WVABQfr+T9NbsZO/Wbk/LdmHPiwt29fTTz77u4ycrodP48AQwC8o0xWwDshd/HAt975BkLzDLWW2VLRCRORFLsheGP2nlC7U/LefNMKXXaHvtoPc99uYW//OgcjpZX8pd5693Hljw4kk37Sjg/ox0RocHcd2kPoiNCCA9pvROvNUf+BIBUYKfHfgEw2I88qUCh/QSxAugOTDXGLPXIN1lEJgC5wK+MMYe8f1xEJmI9VZCero94SrUEZZXVPPflFgAeevs72nm0y985rCsdYiNqDclMiA5v8jIq/2YD9dWd7n0XX2ceY0y1MaY/kAYMEpG+9vFpQDespqFC4ElfP26MmW6MyTbGZCclOestPaVaqsVbrKGbsZGh/PLSTA4dq6BD2wg2PjqaB0f3DnDpVA1/ngAKgE4e+2nA7obmMcYcFpEvgFHAWmPM3ppjIvI88L7/xVZKNUcVVS6CBG7993IA/jGuP8N7tueC7okcr6gmLKT1T7DWkvgTAJYDmSLSBdgFjANu8MozF6s5ZzZW81CxMaZQRJKASvviHwlcCjwO4NFHAPAjYC1KqRZj4aYi9hSXce3ANESEapdh0F8+5fCxSneenK4JAJyf0S5QxVSnUG8AMMZUichk4GOsYaAzjDHrRGSSffxZYB7WENB8rGGgt9qnpwAz7X6AIGCOMabmTv9vItIfq6loG3BnY1VKKXX23fTiMgC+2FjE49ecy7b9pbUu/jN/NqhVr6bVGuh00Eqp05Ix5QMAggS6JEaxuagUgAlDOtMjOYYbczoHsnjKQ13TQWuDnFKqQcoqq3nqkw0A5HRtx6u351B8vMp9/P7LeujFv4XQAKCUapAFeft45rN8APp3imdItwTm3XMhF3ZP5IHLexLXRqdiaCl0LiClVIPMXb0LsJp9rrXn5GnfNoJXbvd+PUg1dxoAlFJ+qXYZgoOEuEjrDv+zXw3DmgZMtVQaAJRS9fquoJir//UNQ7slsHDTfgC9+LcCGgCUUnXad6SMO2blsrrAmqO/5uKvWgftBFbKoSqrXWwpOurzWFllNS8s3MKgvyxwX/wBfn9Fb2IiQvjLj85pqmKqs0ifAJRyqLe+LeC3b37HzUM684crs2qtn7tq52Ee/SDPvX/HRV24KSeD9IQ23HZhF23+aSU0ACjlUL998zsAZi7ezoa9Jfxz/ACSYqxZOUvLT4zrn3FLNiN6Jbv39eLfemgAUMpBjlVU8cTHG/FcMvep6/vx0NvfceU/F/Kvnw4gOjyU2cut2d3n33cxmckxASqtOts0ACjlEAeOljPw0U9rpd2Yk86PB6TRO6UtP39lBT95bglVrhPTw3Rq16api6makHYCK+UQqwsO19pvHxPunpu/d0pb3p18IZf0au8+nhYfqZO5tXL6BKCUQ2yxJ2v789g+jB+UTkiQ1GrPj40M5bkbB/LGip1kpcSSmRwdqKKqJqIBQCmHWJC3D4Ax56QQGuz74T8oSPjJ+br0qlNoE5BSDlGzTGOirr+rbH4FABEZJSIbRCRfRKb4OC4i8ox9fI2IDLDTI0RkmYisFpF1IvKIxzntRGS+iGyy/8Y3XrWUUp48h3UqVaPeAGCv5jUVGA1kAeNFJMsr22gg0/5MxFrwHaAcGGGM6Ye1+PsoEcmxj00BFhhjMoEF9r5SqpGVVVbT508fA/DDfh0DXBrVnPjTBzAIyDfGbAGw1/0dC3zvkWcsMMtYy4stEZE4jzV/a941D7U/xuOc4fb2TOAL4LenXxWlVA1jDO+s2sXizQfomnSiM/fWCzICVyjV7PgTAFKBnR77BVgLv9eXJxUotJ8gVgDdganGmKV2nuSaReHtBeTbo5RqFH/9cD3Tv9pSK+1v15zLeZ3iAlMg1Sz50wfg671v74WE68xjjKk2xvQH0oBBItK3IQUUkYkikisiuUVFRQ05VbVg1S7DvpIyfvD3L3kjdydHy6vYfqCUb/L388m6PYEuXrO190gZa3cVn3TxT4uP5PrzO+k0DqoWf54ACoBOHvtpwO6G5jHGHBaRL4BRwFpgb00zkYikAPt8/bgxZjowHaxF4f0or2oFnpq/gamfbwbggf+u4Z1Vu/gm/4D7+Mu3DeKizKRAFa9Z2nX4OCOe+ILyKpc7bcXvLyU0JEg7gZVP/jwBLAcyRaSLiIQB44C5XnnmAhPs0UA5QLF9YU8SkTgAEYkELgXWe5xzs719M/DumVVFtSardh6ute958QeY/NpKtu0vbcIS+aey2sUlT3zBn95dy/YDpcxavI2qaletPBVVLl76ZisHSysa/P1fbizirW8LsLrbYE9xGbOX7aCy2sWNLyytdfGfNKwbCdHhtI0IJSU28swqplqlep8AjDFVIjIZ+BgIBmYYY9aJyCT7+LPAPGAMkA8cA261T08BZtr9AEHAHGPM+/axx4A5InIbsAO4rvGqpVo6zwv+PSMzmfp5PtUuQ3hIEBkJUewtKeP2Wbm8fddQyipdtI0MISQoCJcx7pecSsoqOV5RTfu2EU1W7pKyKrbuL2Xr/lLeWFHAsYpqvtpYxD/HDyAyzJpW4T/Ld/Dwe9/z8Hvf8+n9w+je3vcbt68v20FkaDA/6JPMiu2HuLB7ItO+yGfJloN8k3+AC7oncP+c1QA8/N46yiqti///XN2XTvGR9E2NbZpKqxZLau4kWoLs7GyTm5sb6GKoJpAx5QMAvv3DZcS3CeWNFQVsP1DKyN7JRIWFcKC0nJteXMbwHkks2nwAg2FEr/bM/34vub+7jNg2ofxy9kreWbWbefdcRFbHtg0uQ/6+EjrGRdImzP8X5guLjzPkr5+R3DacvUfKARCBfmlxvHhzNsu2HuTnr37rzh8TEcK0nw7kwszEOv8NQoOFymrD8J5J7Dx4jAOlFRw+Vunz968dmMYT1/VrSDWVA4jICmNM9knpGgBUc3P4WAX9/zyfkb3a8+It59eZb9bibfzx3XUnpQ/q0o6XbxtEz99/BFhvvr7186GkJ/ie2dIYw54jZZSWV7Fw035uHpKBCHR5cB5gBaF2UWF+lX30PxaSV3iEJ6/rR0W1i/WFRxjaPZF7Xl9J+7bh7Dx43J133j0Xcd9/VpFfdJQ/j+3DTwd3BuCTdXuYu3o3768p9PkbV/fvyA/7deS2mdb/F/73R30Z2DmemYu289CYXsREhPpVVuUcdQUAnQtINTs1zT8b9pacMt9NOZ3JKyzh9WU7aqUv23qQm2csc+9XuVzc+OJS/vvzIbSPObk5aPm2Q1z/3GL3/vrCEu69NNO9P376El65fbB7sRRvT32ygeTYCMafn05e4REAEqLDGN7zxMjm1+7I4faZy937z900kKyObfnvz4fwi9dX8ru317J5XynRESE8s2CTO98jV/Uhrk0oX2/azw/7deSe2StJb9eGkb2TWfLgSMoqq8lIjALgrz/WZRpVw+gTgGp2Jr/2Le+vKeTft57PJT1P/XpIZbWLxz9cz5hzU/h8/T7S4iM5fKySv35ojTW4bmAa4wen89Pnl5KRGMV/7syhbUQoLpfhL/PyuPq8VObk7mTW4u21vrd9TDj7SsoZ3KUdawqKSYmN4NU7Brs7U6uqXRw6VsmSLQf4xesrARjWI4kvNxbRMzmGD++9iKCg2kMutxQd5ZH3vuc3o3rSp+OJ9vmqahePfpDHS4u21crfJTGKV28fTMe4Ex24ZZXVhIcE6XBO1SDaBKSanTtfzqVdVBh//fG5tdJr2r6/euCSOpttTsUYw8Nz1zFz8XZ3EPlyYxG3z1zOeenxPHldPx6eu44F62uPPM7ubE1HNbR7ovsu/OvfXsKe4jJu+fdy4qNCeeSqPvzj002kJ0Tx3mrv0dCW5ydkc1lWss9jp/Lyku384Z21xISHMOPW8zk/o12Dv0MpX7QJSDWZ3G0Hqaw2DOmWcNKxkrJK2oSFEBwkfLxuLwA5XRO4ql9Hio9XEtfmRFt7p3anN3RRRPjjD/swvGd7Luhmda4O65HEk9f3597ZK7l66jcc8BqCGSTwxqQh7vNDgoTZy3aQGB1OWnwbXrl9MBNeXMrPXrJuQFYXFNc6/+27hvLVxv1M/2oz/Tqd3uibm3I6MyijHTERIbXu+pU6WzQAqEY3brq1rOBnvxpWax4agKGPfUa7qDBevf3EbCIPvvUdRSXlPPpBHncN7wZYzR9n0swRHCS1VrcCuKpfR46WVfHQ29+50/4xrj+Pf7iey7KSa/3ePSMz+cWI7u60/p3ieH1iDlc88zVgjd4JDhIu653M0O4JnJcez3np8Uwe0Z3goNMvd88Ouv6uajoaAFSjOlpe5V5T9r45q/nvpCHucflfb9pPSVkVJWVV3Ppvq0O0R3I0B0srePSDPAD+9YX19u+1A9POSvluGJxOZbWLZ7/czCf3XUxMRCiX9+ngc4EU7wDUp2Msn/96OB+uLeSWoRkcOlZJqted+plc/JVqatoHoBrFhj0l/PXDPJJjIvhP7ol5Ae8Zmcn9l/UATrTte5p3z0UcOlbBjS8uxfM/xTcmDTmrbeDGGO1IVY5RVx+Argimztj3u4/wzIJNfLGhyH3xH9u/Iz8ekMrUz/P5dsehWvlvzEmnY6w1HLNDbAQXdE/kgct7EhMRwvMTsumSGEV6u4Z3/jaEXvyV0iYg1Qhu+fcy9pWU10p78rp+HKusZumWg9z3n1XMnmitA9Q7pS2/G5PFuPPTeWflLuLbWC8t3TW8O3dc1JXQ4KDTGkGjlGo4fQJQZywm4sR9RNekKGIjQwkJDqJtRChPXd+PHQePuUfPdE2MIjIsmL6psfz+yqxad+J1LVSulDo79AlAnZE9xWVsLrJm5eyXFsuLt5xP4eEy9/HBXRP4xSXdeeazfMDqhFVKNQ96y6UabMX2gxQWW3Pa5O054k5/d/KFJEaHc05a7XHw94zMZFAXq0M3REfJKNVs6BOAarBrplnz5mx4dBRLtljz9vzrpwPqzB8SHMQ/x5/HtC82nxQclFKBowFANUjutoPu7ac/3cRzX1pLD3aKP/WoneS2ETx8VZ+zWjalVMNoE5BqkGufPTFr5nNfbnZvp8br1AVKtTR+BQARGSUiG0QkX0Sm+DguIvKMfXyNiAyw0zuJyOcikici60TkXo9zHhaRXSKyyv6MabxqqbPt4h5JdLBX2rpzWFe/58tXSjUf9QYAeznHqcBoIAsYLyJZXtlGA5n2ZyIwzU6vAn5ljOkN5AB3e537d2NMf/sz78yqopqCCCRGh/GnH2bxt2utlaciQoIDXCql1Onwpw9gEJBvjNkCICKzgbHA9x55xgKzjDWvxBIRiRORFGNMIVAIYIwpEZE8INXrXNVCFB+vxBgYkB5Pt6RouiVF8+rtg3UCM6VaKH+agFKBnR77BXZag/KISAZwHrDUI3my3WQ0Q0Tiff24iEwUkVwRyS0qKvKjuOpsOWhPoex5wb+geyKJ0b5XylJKNW/+BABfA7e9Z5A7ZR4RiQbeBH5pjKkZOD4N6Ab0x3pKeNLXjxtjphtjso0x2UlJSX4UVzW24uPWAuTVLhcAPZL1jl+p1sCfJqACoJPHfhrgvRRSnXlEJBTr4v+qMeatmgzGmL012yLyPPB+g0qumkTx8Ur6PfIJP8nuxEU9rMVVql0tZwZZpVTd/HkCWA5kikgXEQkDxgFzvfLMBSbYo4FygGJjTKFYE728COQZY57yPEFEUjx2fwSsPe1aqLPmiH33/5/cnXy4dg9Qe+4fpVTLVe//k40xVSIyGfgYCAZmGGPWicgk+/izwDxgDJAPHANutU+/ALgJ+E5EVtlpD9kjfv4mIv2xmoq2AXc2Up1UI8orPDHVwwdrCgHom6pv8yrVGvh1K2dfsOd5pT3rsW2Au32c9zW++wcwxtzUoJKqgJj48goArjg3xR0AdD4fpVoHfRNY1XLFMwt51n7Dt7La5U6fdHE3bhicTmiwEBmm4/6Vag20MVe5uVyGdbuPsGFPCRd2T+SR99YBcFlWMuekxZLVsS93XtyVNmH6n41SrYH+P1m5VdrDPKtchl+/sZr1e0oAWLXzMGAteN45ISpQxVNKNTJtAlJuldXW8M6cru3cF3+AKaN6BapISqmzSAOAcqussp4ARvXpwI8HWC9y//i8VK4ZmBbIYimlzhINAMqtptM3NCSIP13Zh9S4SJJidJoHpVor7QNwuOe+3EznhCgu75PMP+11e0ODgohtE8qn9w8jPETvEZRqrTQAONxfP1wPwNt3DeXlJdutRHuYvw73VKp109s7BcBv31zj3o5vo4u7KOUEGgAcrl1UGGEhQWzcexSAyZd0Z2Sv9gEulVKqKWgAcLiqahc3DEpnWA9rqu0uiVEE6VQPSjmCBgCHq3YZQoKEx645h0Fd2pHVsW2gi6SUaiIaABzEGMOi/P1UeczxU+UyBAcLKbGRzLlzCL1TNAAo5RQaABwkr7CEG15YyqRXvgXg5SXbKa9yESza5KOUE2kAcJDjldUAfJq3l1U7D/OHd6w1ePYcKQtksZRSAaIBwEFc5sRSjr+as8q9PaRrQgBKo5QKNL8CgIiMEpENIpIvIlN8HBcRecY+vkZEBtjpnUTkcxHJE5F1InKvxzntRGS+iGyy/8Y3XrWULzc8vwSAuy/pxuaiUgCuG5jGddmdTnWaUqqVqjcAiEgwMBUYDWQB40UkyyvbaCDT/kwEptnpVcCvjDG9gRzgbo9zpwALjDGZwAJ739EKi49z339WUXys0q/8xyuqefCtNew+fPyU+SqqXJRVVrtn+7w4M4kbBqcDsGV/6ZkVWinVYvnzBDAIyDfGbDHGVACzgbFeecYCs4xlCRAnIinGmEJjzLcAxpgSIA9I9Thnpr09E7j6zKrS8n36/V7eXrmL37+71q/8eXuO8PqynVz61JenzHfrS8vo/cePAAgNFs5Lj+ehMb2JaxPKFeeknHG5lVItkz8BIBXY6bFfwImLuN95RCQDOA9YaiclG2MKAey/Pl8/FZGJIpIrIrlFRUV+FLflio+ypmB4b/VuyuwOW09lldUYYzDG8OLXW9lTbHXeHquo5pv8/Sfl/+O7a/lobSHf5B+gpvn/9ou6EhYSRHR4CCv/cBk/u7DL2auQUqpZ8ycA+BojaBqSR0SigTeBXxpjjvhfPDDGTDfGZBtjspOSkhpyaovj8vhXfXfVrpOO9/3Tx0yYsYz9Ryv4n/e/565Xv3Uf+/N731NV7eLA0XKe+HgDxyqqmLV4O5Ne+ZbUuEh3Ps8F3UWHfyrlaP7MBloAePYSpgG7/c0jIqFYF/9XjTFveeTZW9NMJCIpwL6GFr61MfZtemRoMM8v3Mp1AzvVmpahymVYuGk/m/aV1DpvwpDOzFq8ndeW7SAyNJj/+zyfvMITcXbX4eMMSI/jSFkV3dtHN01llFLNnj9PAMuBTBHpIiJhwDhgrleeucAEezRQDlBsX9gFeBHIM8Y85eOcm+3tm4F3T7sWrUS1/Qgw8eKu5O87yucbfMfExz/aUGt/dN8UhnZL4MlPNnK0vAqABeutc6PDrRifGB3Op/cPY2x/79Y7pZRT1RsAjDFVwGTgY6xO3DnGmHUiMklEJtnZ5gFbgHzgeeAuO/0C4CZghIissj9j7GOPAZeJyCbgMnvf0e6fsxqAq/p3pGNsBFM/z3c/FYC1KDvAanuR9kt7JwOQGB3GI1f14VhFlXtRlxo/uyCDy/sk0z897uxXQCnVovi1IIwxZh7WRd4z7VmPbQPc7eO8r/HdP4Ax5gAwsiGFdYqw4CDuuqQ7v39nLV9t2u+eqdNlDLdd2IUXv94KwOi+Hfh/157r7jy+8+Ju/N/nVgB4+IdZPPze94SHBvPcTdmBqYhSqlnTN4GbodS4SK7P7kTH2Aj+Pn+je+SPMVaTzuRLugPW1A41F3+AySO60yUxCoDL+nRg+k0DuV5f8lJK1UGXhGwGPlu/l/1HK4gMDebGnHSCgoSwIOHuEd353dtr+WJjERd1TwSsZqBfjOhOp3aRjPEawx8RGswT1/XjuS83kxQdzg/6dAhEdZRSLYQGgGbgZy/lAhAkEOQxNPO6gZ341+ebeXr+RoZ2s+brCQ4SQoKD+Mn56T6/a2DneKZP0CYfpVT9tAmoGeiWZDXbuAy1hn2GhQRx78hMVhcU88GaQgB06L5SqrE4PgDMWb6T/64oCGgZ0uLbuLe9V2O8ZmAavTrE8PhH6wF07n6lVKNxfAD4zZtr+PUbqwNaBpcxhIVY/1OEBNX+nyQ4SHhoTG/2Hil37yulVGPQPoBmwGUM56TGctuFXejXKe6k4xf3SGJYjyS+3FhUq49AKaXOhOOfAGp4vnDVlBbl7+eb/ANUuwxjzkmpNW+Pp99d0Zuw4CDio0KbuIRKqdZKnwBspRXV7mkTmtKMb7YBsMp+u7cuPZJjWPTgCNq1CTtlPqWU8pc+AdiKSsoD8rtZHdsC0De1bb15E6PDa40SUkqpM6EBwLb/qH8B4LuCYsqrTp6r/7TZTU9v3Dm08b5TKaX84PgAEBkaDPj3BFBSVskP/+9r7nrl23rz+sMYQ7UxBAcJkWHBjfKdSinlL8f3ASTFhLPj4DG/ngBq1tStmWr5TI2d+g1rCooJDdZmHaVU03P8E0B8G2tUzX4/ngA8RwpVVrvO+LfXFBTb3xWYEUhKKWdzfACo6VQt8uMJwPMyvabgMACFxcf55eyVHCmrPAulU0qps8evACAio0Rkg4jki8gUH8dFRJ6xj68RkQEex2aIyD4RWet1zsMissvHQjEB4U8fgOerAku2HATg3VW7eWfVbp6ev8nv31q+7SAlZZUkRuuQTqVU4NQbAEQkGJgKjAaygPEikuWVbTSQaX8mAtM8jr0EjKrj6/9ujOlvf+bVkeesqrmo7zlSVn9ej2eAJVsOANDJnsfno7WFfv1eVbWL655dzPD/9wUuAzcMTmfNwz9oYKmVUurM+fMEMAjIN8ZsMcZUALOBsV55xgKzjGUJEGcv9I4x5ivgYGMW+mzYfbj+AFBz/Q8NFnK3HaK8qtodFHYXl1F8vP5moCp73d8DpRWUlFUSGiS0jdC3e5VSTc+fAJAK7PTYL7DTGprHl8l2k9EMEYn3lUFEJopIrojkFhUV+fGVp+dgaQXHK049vr/m/n9YjySOV1azbOvBWs1CC/L21s5fz/QSldUG0bl9lFIB4k8A8HWF8r6y+ZPH2zSgG9AfKASe9JXJGDPdGJNtjMlOSkqq5ysbzrOQhcXHT53XzjykWyLhIUF8tn5frfPnfbfHvf3w3HX0/dPHtYLA5qKjVLtq/7Po5G5KqUDxJwAUAJ4Ly6YBu08jTy3GmL3GmGpjjAt4HqupKSAiQq1/hvqagWqae9qEBTOkWwKfr9/nvsAP75nEVxuLOHysAoCXFm2jtKLa3VlcWHyckU9+yZS3vgPgzmFdiQoLpm2k41/FUEoFiD8BYDmQKSJdRCQMGAfM9cozF5hgjwbKAYqNMafsFa3pI7D9CFhbV96zraM9A+fuUzwBFJWU88k6q4lHgBG92rPtwDG2FJUCcM2ANCqqXbxnr9w1old7AF5atBWA0nKreem91VZcTIoOZ/79w7jz4m6NXyGllPJDvQHAGFMFTAY+BvKAOcaYdSIySUQm2dnmAVuAfKy7+btqzheR14HFQE8RKRCR2+xDfxOR70RkDXAJcF9jVapBjCElNgIR2H247gDw+3e+409z17n3L+lpXeAXrLeCQt/UWHp1iOG/uVZXSFiw9U87//u97Dx47KT+gCAROsZF6hQQSqmA8av9wR6iOc8r7VmPbQPcXce54+tIv8n/Yp5docFBJEWHU3iKJqDwkBMXahHo1K4NvTrEsHbXESsNuHZgGo9+kMfGvSUYDG0jQiitqOaVJdv58YC0Wt+nTf9KqUBz7JvAB46W17orT4uPZMfBY3Xmz2wf7d4Wu8/7inNOtGKJwNXnpRISJPx3RQEuYzUtjerbgdeW7XD3Ddx6QQYAEaF656+UCixHBoCdB48x8NFPeWHhVvconozEKLYdKK2Vb+v+Uo6WV9X5PVeceyIABImQGB3OyN7teSN3J2WV1QSJ8PNh3Sgpq+KlRdsAyOmawOt35HBVv46NXS2llGoQRwaAmpk/31tjdcgK0CUhisLislrvAlzyxBeM+cdCoPZw0Q17SwDomhRNVkrthVxuHprBoWOVLNy0HxGrb+DS3u35cO0e928N6ZZAVABWH1NKKU+ODACxkdabtwdLK9xj+zMSowBOegqoaRby7MO9MDPRvf1D+04+3B5KOqRrAj2TY4AT7fy/GJHpzq/j/pVSzYUjA0DNRfhgqdUuLyJ0qQkA+0tPyl98vNL9DsCWv4xxjwACuO3CLrx2x2Dax0S4v+sWu52/poO4X6c44uxpp49XNuJqYkopdQYcGQBqbuaPeTT31DwBbPERAFbuOOR+AvC+gQ8LCWJot8RaaVf3P3kWjH/91JogNTM5+qRjSikVCI5viK65s48ODyExOtznE0DutkPudQP8mbsnMiyYFyZkuyd+AxjaLZGtfx2jc/8opZoNxwcAODGRUdekKPKLjrrTI0ODOV5ZTe72gwzKaNeg77w0K/nk39GLv1KqGXFkE1BdeneIYeOeElz2nXvN08GqnYcpr3bpy1tKqVbF8QGgymM93l4pbSmtqGbnoRMjfzLbR1NW6SJ326FAFVEppc4KRwYAzzeADx+rdN/Z97bH9OcVlriP53RNIDRYWLH9kM85r5VSqqVyZADwVDMUFKBHcjQisH6PNXzTAG3Cg8nubLX/axu+Uqo1cXwAqKh2ubfbhIWQkRDF+ponAGPN+3NxD2shGu/FXJRSqiVzfACwnLizz0ppy9rdxYDVCSxiLQGplFKtjSMDwKnu4/t3iqPg0HH2lVhTQwvQOyWmScqllFJNyZEB4FQGdI4DYOWOwx5v/woD0uMCViallDob/AoAIjJKRDaISL6ITPFxXETkGfv4GhEZ4HFshojsE5G1Xue0E5H5IrLJ/ht/5tU5PZ59u306xhIaLHy74xDG49jsiUNY9tDIgJRPKaXOhnoDgIgEA1OB0UAWMF5EsryyjQYy7c9EYJrHsZeAUT6+egqwwBiTCSyw9wMuIjSYPh1jWbn9MHBi8ZewkCDat40IYMmUUqpx+fMEMAjIN8ZsMcZUALOBsV55xgKzjGUJEFez6Lsx5ivgoI/vHQvMtLdnAlefRvnPSM200N4GpMezuuCwjvpRSrVq/gSAVGCnx36BndbQPN6SjTGFAPbf9r4yichEEckVkdyioiI/ilu/mrb9lFjrjt5zERiAod0SKK9y2b/fKD+plFLNjj8BwNcl0PvW2J88p8UYM90Yk22MyU5KatzhmOnt2gCctBZwTrcEQmpm/2zUX1RKqebDnwBQAHTy2E8Ddp9GHm97a5qJ7L/7/ChLo6pZBMY7AESHh3CejvpRSrVy/gSA5UCmiHQRkTBgHDDXK89cYII9GigHKK5p3jmFucDN9vbNwLsNKHejSE9oU+exizKtp43DxyubqjhKKdWk6g0AxpgqYDLwMZAHzDHGrBORSSIyyc42D9gC5APPA3fVnC8irwOLgZ4iUiAit9mHHgMuE5FNwGX2fhOxWqdiInx3AgPu6R++3aGzgCqlWie/FoQxxszDush7pj3rsW2Au+s4d3wd6QeAgA6sF2DyJd3dy0F6Ojc1lqv7d2TcoPSmL5hSSjUBx68I9uvLe/pMDwoSnh53XhOXRimlmo5OBaGUUg7lyABg9P0upZRyZgBQSinl8ACgb/kqpZzM0QFAKaWcTAOAUko5lCMDgPYBK6WUQwNADdGp3pRSDuboAKCUUk6mAUAppRzKkQFAXwRTSimHBoAa+h6AUsrJHB0AlFLKyTQAKKWUQ/kVAERklIhsEJF8EZni47iIyDP28TUiMqC+c0XkYRHZJSKr7M+YxqlS/Yy+CaCUUvUHABEJBqYCo4EsYLyIZHllGw1k2p+JwDQ/z/27Maa//ZmHUkqpJuPPE8AgIN8Ys8UYUwHMBsZ65RkLzDKWJUCcvdC7P+cGjPYBK6WczJ8AkArs9NgvsNP8yVPfuZPtJqMZIhLv68dFZKKI5IpIblFRkR/FVUop5Q9/AoCvG2XvRvS68pzq3GlAN6A/UAg86evHjTHTjTHZxpjspKQkP4qrlFLKH/6sCVwAdPLYTwN2+5knrK5zjTF7axJF5Hngfb9LfYb0RTCllPLvCWA5kCkiXUQkDBgHzPXKMxeYYI8GygGKjTGFpzrX7iOo8SNg7RnWpcH0RTCllJPV+wRgjKkSkcnAx0AwMMMYs05EJtnHnwXmAWOAfOAYcOupzrW/+m8i0h+rSWgbcGcj1ksppVQ9/GkCwh6iOc8r7VmPbQPc7e+5dvpNDSqpUkqpRuXIN4G1D0AppRwaAJRSSjk+AGgvsFLKuRweAJRSyrk0ACillEM5MgDobKBKKeXQAFBDXwRTSjmZowOAUko5mQYApZRyKEcGAH0RTCmlHBoAlFJKOTwAaB+wUsrJHB0AlFLKyTQAKKWUQ2kAUEoph3J0ABB9E0wp5WB+BQARGSUiG0QkX0Sm+DguIvKMfXyNiAyo71wRaSci80Vkk/03vnGqpJRSyh/1BgARCQamAqOBLGC8iGR5ZRsNZNqficA0P86dAiwwxmQCC+x9pZRSTcSfJSEHAfnGmC0AIjIbGAt875FnLDDLXhpyiYjE2Yu+Z5zi3LHAcPv8mcAXwG/PsD4+/XPBJuau3u3eL6uqPhs/o5RSLYo/ASAV2OmxXwAM9iNPaj3nJhtjCgGMMYUi0t7Xj4vIRKynCtLT0/0o7smSYsLJTI6ulXZ+RjsGpMed1vcppVRr4E8A8NVT6j2ZQl15/Dn3lIwx04HpANnZ2ac1icO4QemMG3R6wUMppVorfzqBC4BOHvtpwG4/85zq3L12MxH2333+F1sppdSZ8icALAcyRaSLiIQB44C5XnnmAhPs0UA5QLHdvHOqc+cCN9vbNwPvnmFdlFJKNUC9TUDGmCoRmQx8DAQDM4wx60Rkkn38WWAeMAbIB44Bt57qXPurHwPmiMhtwA7gukatmVJKqVMS04LmRs7Ozja5ubmBLoZSSrUoIrLCGJPtne7oN4GVUsrJNAAopZRDaQBQSimH0gCglFIO1aI6gUWkCNh+mqcnAvsbsTgtgdbZGbTOznAmde5sjEnyTmxRAeBMiEiur17w1kzr7AxaZ2c4G3XWJiCllHIoDQBKKeVQTgoA0wNdgADQOjuD1tkZGr3OjukDUEopVZuTngCUUkp50ACglFIO5YgAUN+i9i2FiMwQkX0istYjrZ2IzBeRTfbfeI9jD9p13iAil3ukDxSR7+xjz4iIr4V7mgUR6SQin4tInoisE5F77fRWW28RiRCRZSKy2q7zI3Z6q60zWGuIi8hKEXnf3m/V9QUQkW12eVeJSK6d1nT1Nsa06g/WNNSbga5AGLAayAp0uU6zLhcDA4C1Hml/A6bY21OAx+3tLLuu4UAX+98g2D62DBiCtWLbh8DoQNftFHVOAQbY2zHARrturbbedvmi7e1QYCmQ05rrbJf1fuA14H0n/Ldtl3cbkOiV1mT1dsITgHtRe2NMBVCzMH2LY4z5CjjolTwWmGlvzwSu9kifbYwpN8ZsxVqrYZC9+lpbY8xiY/2XM8vjnGbHGFNojPnW3i4B8rDWmm619TaWo/ZuqP0xtOI6i0gacAXwgkdyq61vPZqs3k4IAHUtWN9aJBtr9TXsv+3t9LrqnWpve6c3eyKSAZyHdUfcquttN4eswloqdb4xprXX+WngN4DLI60117eGAT4RkRUiMtFOa7J6+7MofEt3xgvTt1B11btF/nuISDTwJvBLY8yRUzRxtop6G2Oqgf4iEge8LSJ9T5G9RddZRK4E9hljVojIcH9O8ZHWYurr5QJjzG4RaQ/MF5H1p8jb6PV2whOAP4vat2R77UdA7L/77PS66l1gb3unN1siEop18X/VGPOWndzq6w1gjDkMfAGMovXW+QLgKhHZhtVEO0JEXqH11tfNGLPb/rsPeBurybrJ6u2EAODPovYt2VzgZnv7ZuBdj/RxIhIuIl2ATGCZ/UhZIiI59kiBCR7nNDt2GV8E8owxT3kcarX1FpEk+84fEYkELgXW00rrbIx50BiTZozJwPr/52fGmBtppfWtISJRIhJTsw38AFhLU9Y70L3gTfHBWrB+I1av+e8CXZ4zqMfrQCFQiRX1bwMSgAXAJvtvO4/8v7PrvAGPUQFAtv0f2mbg/7DfCG+OH+BCrMfZNcAq+zOmNdcbOBdYadd5LfBHO73V1tmjvMM5MQqoVdcXa2Tiavuzruba1JT11qkglFLKoZzQBKSUUsoHDQBKKeVQGgCUUsqhNAAopZRDaQBQSimH0gCglFIOpQFAKaUc6v8Du6RPhEZXcH8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(np.arange(len(winrate)),winrate)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(np.arange(len(r_avg_list)),r_avg_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
