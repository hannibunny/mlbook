{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning with Python\n",
    "\n",
    "* Author: Prof. Dr. Johannes Maucher\n",
    "* Email: maucher@hdm-stuttgart.de\n",
    "* Last Update: December, 17th 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goals of this lecture are:**\n",
    "\n",
    "* Understand all steps of the datamining process, from data access to visualisation and interpretation of the results.\n",
    "* Learn how to implement all of these process steps in Python, applying libraries like [Pandas](http://pandas.pydata.org/), [NumPy](http://www.numpy.org/), [Matplotlib](http://matplotlib.org/), [Scikit-Learn](http://scikit-learn.org/stable/index.html) etc.\n",
    "* Learn how to integrate Machine Learning algorithms from scikit-learn into datamining projects.\n",
    "* Understand Neural Networks, in particular Deep Neural Networks\n",
    "* Learn how to implement neural network- and deep neural network applications with [Keras](https://keras.io/).\n",
    "* Understand how to model words and documents for textmining\n",
    "* Learn how to implement methods for text classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='basic_modules'></a>\n",
    "## Prerequisites\n",
    "This course requires basic knowledge of Python, [Pandas](http://pandas.pydata.org/), [NumPy](http://www.numpy.org/) and [Matplotlib](http://matplotlib.org/). Moreover, the Python Machine Learning framework [Scikit-Learn](http://scikit-learn.org/stable/index.html) will be extensively applied in this course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='data_mining'></a>\n",
    "## Contents\n",
    "\n",
    "### Conventional techniques with scikit-learn\n",
    "\n",
    "1. [Basic Concepts of Data Mining and Machine Learning](00BasicConcepts.ipynb)\n",
    "    * Definition\n",
    "    * Categories\n",
    "    * Validation\n",
    "    \n",
    "2. [Regression Model](02RegressionPipe.ipynb)\n",
    "    * Example Data: Insurance Data\n",
    "    * Entire Data Mining process from data access to evaluation  \n",
    "    * One-Hot-Encoding\n",
    "    * Scaling\n",
    "    * Learn and apply Regression Model\n",
    "    * Evaluation Metrics for Regression Models\n",
    "    \n",
    "3. [Classification Model](03ClassificationPipe.ipynb) \n",
    "    * Example Data: Cleveland Heart Disease Dataset\n",
    "    * Cleaning, One-Hot-Encoding\n",
    "    * Building a pipeline of modules for scaling, transformation and classification\n",
    "    * Evaluation of a Classifier by accuracy, confusion matrix, precision, recall, f1-score\n",
    "    * Cross-Validation\n",
    "    * Determine feature importance\n",
    "    * Fast and efficient model comparison\n",
    "    \n",
    "5. [Ensemble Methods: General Concept](05EnsembleMethods.ipynb) \n",
    "    * Categorisation of ensemble machine learning algorithms and the main concepts\n",
    "    \n",
    "5. [Hyperparameter Optimisation](05Optimisation.ipynb)  \n",
    "    * Example Data: Predict bike rental\n",
    "    * Train and evaluate Random Forest Regression model\n",
    "    * Error visualisation\n",
    "    * Determining feature importance\n",
    "    * Hyperparameter Tuning\n",
    "    * Fast and efficient model comparison\n",
    "    * Comparison with Extremly Randomized Trees\n",
    "    \n",
    "    \n",
    "### Neural Networks and Deep Neural Networks\n",
    "\n",
    "11. [Conventional Neural Networks](01NeuralNets.ipynb) \n",
    "    * Natural Neuron\n",
    "    * General Notions for Artificial Neural Networks\n",
    "    * Single Layer Perceptron (SLP)\n",
    "        * Architectures for Regression and Classification\n",
    "        * Gradient Descent- and Stochastic Gradient Descent Learning\n",
    "    * Gradient Descent- and Stochastic Gradient Descent Learning\n",
    "    * Multilayer Perceptron (MLP) Architectures for Regression and Classification\n",
    "    * Backpropagation-Algorithm for Learning\n",
    "    \n",
    "\n",
    "12. [Recurrent Neural Networks (RNN)](02RecurrentNeuralNetworks.ipynb) \n",
    "    * Simple Recurrent Neural Networks (RNNs)\n",
    "    * Long short-term Memory Networks (LSTMs)\n",
    "    * Gated Recurrent Units (GRUs)\n",
    "    * Application Categories of Recurrent Networks\n",
    "\n",
    "\n",
    "13. [Deep Neural Networks: Convolutional Neural Networks (CNN)](03ConvolutionNeuralNetworks.ipynb) \n",
    "    * Overall Architecture of CNNs\n",
    "    * General concept of convolution filtering\n",
    "    * Layer-types of CNNs: \n",
    "        * Convolution, \n",
    "        * Pooling, \n",
    "        * Fully-Connected\n",
    "        \n",
    "\n",
    "14. [MLP and CNN for Object Classification](03KerasMLPandCNNcifar.ipynb)\n",
    "    * Example Data: Cifar-10 Image Dataset\n",
    "    * Image Representation in numpy\n",
    "    * Define, train and evaluate MLP in Keras\n",
    "    * Define, train and evaluate CNN in Keras \n",
    "    \n",
    "    \n",
    "19. [Apply pretrained CNNs for object classification - original task](04KerasPretrainedClassifiers.ipynb)\n",
    "    * Access image from local file system\n",
    "    * Download and apply pretrained CNNs for object recognition in arbitrary images\n",
    "    \n",
    "\n",
    "    \n",
    "20. [Use of pretrained CNNs for object classification - new task: Classify x-ray images of lungs into healthy and covid-19](05KerasPretrainedCovid.ipynb)\n",
    "    * Download pretrained feature-extractor (CNN without the classifier part)\n",
    "    * Define new classifier architecture and concatenate it with pretrained classifier\n",
    "    * Fine-tune network with task-specific data\n",
    "    * Apply the fine-tuned network for object-recognition\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "15. [Time-Series Prediction with Recurrent Neural Networks (LSTM) - Prediction of Bike rentals](06KerasLSTMbikeRentalPrediction.ipynb)\n",
    "    * Data Visualisation for Time-Series\n",
    "    * Building Recurrent Neural Networks with Keras\n",
    "    * RNN in many-to-one architecture\n",
    "    \n",
    "    \n",
    "    \n",
    "16. [Modelling of Words and Texts / Word Embeddings](11ModellingWordsAndTexts.ipynb) \n",
    "    * Concept of Word-Embeddings\n",
    "    * Skip-Gram and CBOW\n",
    "    * Working with pretrained word-embeddings\n",
    "    \n",
    "    \n",
    "    \n",
    "14. [Text Classification with CNNs and LSTMs](08TextClassification.ipynb)\n",
    "    * Example Data: IMDB-Movie Reviews for Sentiment Classification\n",
    "    * Text preprocessing and representation with Keras\n",
    "    * Load and apply pretrained word-embedding\n",
    "    * News classification with CNN\n",
    "    * News classification with LSTM\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Additional Jupyter Notebooks    \n",
    "    \n",
    "\n",
    "1. [Feature Selection and Extraction](12FeatureSelection.ipynb)\n",
    "    * Univariate Feature Selection Tests\n",
    "        * Entropy\n",
    "        * Mutual Information\n",
    "        * $\\chi^2$-Test\n",
    "        * F-Measure\n",
    "    * Variance Threshold\n",
    "    * Feature Selectors in scikitlearn: SelectKBest and SelectPercentile\n",
    "    * Principal Component Analysis (PCA)\n",
    "    * Linear Discriminant Analysis (LDA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "nav_menu": {},
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
