
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Graph Neural Networks (GNN) &#8212; Machine Learning Lecture</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet" />
  <link href="../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx-book-theme.5f77b4aec8189eecf79907ce328c390d.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Sequence-To-Sequence, Attention, Transformer" href="../transformer/attention.html" />
    <link rel="prev" title="Text classification with CNNs and LSTMs" href="../text/02TextClassification.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
      <img src="../_static/hdmlogomed.jpg" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Machine Learning Lecture</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../intro.html">
   Intro and Overview Machine Learning Lecture
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Introduction
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../00BasicConcepts.html">
   Basic Concepts of Data Mining and Machine Learning
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Conventional ML
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../machinelearning/knn.html">
   K - Nearest Neighbour Classification / Regression
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../machinelearning/parametricClassification1D.html">
   Bayes- and Naive Bayes Classifier
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../machinelearning/LinReg.html">
   Linear Regression
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../machinelearning/heartRateRegression.html">
   Example Linear Regression
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../machinelearning/LinearClassification.html">
   Linear Classification
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../machinelearning/svm.html">
   Support Vector Machines (SVM)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../machinelearning/gp.html">
   Gaussian Process
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../machinelearning/GaussianProcessRegression.html">
   Gaussian Process: Implementation in Python
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Neural Networks
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="01NeuralNets.html">
   Neural Networks Introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="02RecurrentNeuralNetworks.html">
   Recurrent Neural Networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="03ConvolutionNeuralNetworks.html">
   Convolutional Neural Networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="convolutionDemos.html">
   Animations of Convolution and Deconvolution
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="03KerasMLPandCNNcifar.html">
   Implementing Neural Networks with Keras
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="04KerasPretrainedClassifiers.html">
   Applying Pretrained Deep Neural Networks for Image Classification
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="05KerasPretrainedCovid.html">
   Apply Pretrained Neural Networks on new Task
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Autoencoder
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="04VariationalAutoencoder.html">
   Variational Autoencoder (VAE) to generate handwritten digits
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  GAN
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../gan/GAN.html">
   Generative Adversarial Nets (GAN)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../gan/DCGAN.html">
   DCGAN Keras Implementation
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Reinforcement Learning
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../rl/reinforcement.html">
   Reinforcement Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../rl/DQN.html">
   Deep Reinforcement Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../rl/QLearnFrozenLake.html">
   Example Q-Learning
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Text
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../text/01ModellingWordsAndTexts.html">
   Representations for Words and Texts
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../text/02TextClassification.html">
   Text classification with CNNs and LSTMs
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Graph Neural Networks
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Graph Neural Networks (GNN)
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Transformer
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../transformer/attention.html">
   Sequence-To-Sequence, Attention, Transformer
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../transformer/intent_classification_with_bert.html">
   Intent Classification with BERT
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  References
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../referenceSection.html">
   References
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/neuralnetworks/GraphNeuralNetworks.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/executablebooks/jupyter-book/master?urlpath=tree/neuralnetworks/GraphNeuralNetworks.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Graph Neural Networks (GNN)
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#graph">
     Graph
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#graph-neural-networks">
     Graph Neural Networks
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#message-passing">
       Message Passing
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#graph-convolutional-network-gcn">
       Graph Convolutional Network (GCN)
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#graph-convolutional-network-for-node-classification">
       Graph Convolutional Network for Node Classification
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#graph-convolutional-network-for-graph-classification">
       Graph Convolutional Network for Graph Classification
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#introductory-example-node-classification-with-graph-neural-networks">
   Introductory Example: Node Classification with Graph Neural Networks
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#introduction">
     Introduction
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#setup">
     Setup
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#prepare-the-dataset">
     Prepare the Dataset
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#download-the-dataset">
       Download the dataset
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#process-and-visualize-the-dataset">
       Process and visualize the dataset
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#split-the-dataset-into-stratified-train-and-test-sets">
       Split the dataset into stratified train and test sets
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#implement-train-and-evaluate-experiment">
     Implement, Train and Evaluate Experiment
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#implement-feedforward-network-ffn-module">
     Implement Feedforward Network (FFN) Module
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#build-a-baseline-neural-network-model">
     Build a Baseline Neural Network Model
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#prepare-the-data-for-the-baseline-model">
       Prepare the data for the baseline model
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#implement-a-baseline-classifier">
       Implement a baseline classifier
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#train-the-baseline-classifier">
       Train the baseline classifier
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#examine-the-baseline-model-predictions">
       Examine the baseline model predictions
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#build-a-graph-neural-network-model">
     Build a Graph Neural Network Model
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#prepare-the-data-for-the-graph-model">
       Prepare the data for the graph model
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#implement-a-graph-convolution-layer">
       Implement a graph convolution layer
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#implement-a-graph-neural-network-node-classifier">
       Implement a graph neural network node classifier
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#train-the-gnn-model">
       Train the GNN model
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#examine-the-gnn-model-predictions">
       Examine the GNN model predictions
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="graph-neural-networks-gnn">
<h1>Graph Neural Networks (GNN)<a class="headerlink" href="#graph-neural-networks-gnn" title="Permalink to this headline">¶</a></h1>
<p>Graph based deep learning is currently one of the hottest topics in Machine Learning Research. In the NeurIPS 2020 conference GNNs constituted the most prominent topic, as can be seen in this <a class="reference external" href="https://github.com/naganandy/graph-based-deep-learning-literature/blob/master/conference-publications/folders/publications_neurips20/README.md">list of conference papers</a>.</p>
<p>However, GNNs are not only subject of research. They have already found their way into a wide range of <a class="reference external" href="https://medium.com/criteo-engineering/top-applications-of-graph-neural-networks-2021-c06ec82bfc18">applications</a>.</p>
<p>Graph Neural Networks are suitable for Machine Learning tasks on data with structural
relation between the individual data-points. Examples are e.g. social and communication networks analysis, traffic prediction, fraud detection, etc. <a class="reference external" href="https://www.cs.mcgill.ca/~wlh/grl_book/">Graph Representation Learning</a>
aims to build and train models for graph datasets to be used for a variety of ML tasks.</p>
<p>This lecture shall provide an understanding of the basic concepts of Graph Neural Networks and their application categories.</p>
<div class="section" id="graph">
<h2>Graph<a class="headerlink" href="#graph" title="Permalink to this headline">¶</a></h2>
<p>A graph consists of a set of nodes, which are partially connected by edges. <strong>Nodes</strong> can represent things of different categories such as persons, locations, companies, etc. Nodes may also represent things of the same categorie but different subcategories. <strong>Edges</strong> can be directed or undirected. They also may have weights, which somehow define the <em>strength</em> of the connection. Edges can also be of different type, e.g.</p>
<ul class="simple">
<li><p>an edge between a node of type <em>person</em> and a node of type <em>paper</em> may have the meaning <em>isAuthorOf</em></p></li>
<li><p>a directed edge between two nodes of type <em>paper</em> may mean that the paper of the source node refers to the paper of the target node.</p></li>
</ul>
<figure align="center">
<img src="https://maucher.home.hdm-stuttgart.de/Pics/graph.png" width="500px" align="center">
<figcaption>
Figure 1: Example graph with undirected edges (no arrows) and different node types (colours)
</figcaption>
</figure></div>
<div class="section" id="graph-neural-networks">
<h2>Graph Neural Networks<a class="headerlink" href="#graph-neural-networks" title="Permalink to this headline">¶</a></h2>
<p>In the context of GNNs each node is described by a set of features (a numeric vector). For example, if the nodes represent papers, then the descriptor vector of the nodes may be the Bag-of-Words vector (BoW) of the paper.</p>
<figure align="center">
<img src="https://maucher.home.hdm-stuttgart.de/Pics/graphNodeDescriptors.png" width="550px" align="center">
<figcaption>
Figure 2: To each node a descriptor (numeric vector) is assigned.
</figcaption>
</figure>
<p>The BoW of a paper depends only on the words, which appear in the paper. Information about the neighbouring nodes is totally ignored. On the other hand, in some applications such information from neighbouring nodes may be helpful. For example, it may be easier to determine the subject of a paper, if not only the words in the paper itself are known, but also the contents of the papers in it’s immediate neighbourhood. This is actually what GNNs provide: <strong>GNNs calculate node representations (embeddings), which depend not only on the contents of the node itself, but also on the neighbouring nodes.</strong> The definition of <em>neighbourhood</em> depends on the task and the context. For example the immediate neighbours of a scientific paper may be all papers, which are referenced in this paper.</p>
<div class="section" id="message-passing">
<h3>Message Passing<a class="headerlink" href="#message-passing" title="Permalink to this headline">¶</a></h3>
<p>In a GNN the node representation <span class="math notranslate nohighlight">\(h_i^k\)</span> of each node <span class="math notranslate nohighlight">\(i\)</span> are adapted over many iteration (k indicates the iteration). At the very beginning to each node <span class="math notranslate nohighlight">\(i\)</span> an initial vector <span class="math notranslate nohighlight">\(h_i^0\)</span> is assigned, e.g. the BoW vector of a document. Then in each iteration <span class="math notranslate nohighlight">\(k&gt;0\)</span> these representations are updated by information from the neighbouring nodes. The image below sketches the update of node 0 in iteration <span class="math notranslate nohighlight">\(k\)</span>. Let <span class="math notranslate nohighlight">\(N(i)\)</span> denote the set of direct neighbours of node <span class="math notranslate nohighlight">\(i\)</span>, then</p>
<ol class="simple">
<li><p>For each node <span class="math notranslate nohighlight">\(u\)</span> in <span class="math notranslate nohighlight">\(N(i)\)</span> pass the current descriptor <span class="math notranslate nohighlight">\(h_u^k\)</span> to a Feed Forward Neural Network (for example a single fully connected layer). The output of this FFN is called the message <span class="math notranslate nohighlight">\(m_u^k\)</span> from node <span class="math notranslate nohighlight">\(u\)</span>.</p></li>
<li><p>All messages <span class="math notranslate nohighlight">\(m_u^k\)</span> and the current node representation <span class="math notranslate nohighlight">\(h_i^{k}\)</span> are <strong>aggregated</strong> by some function which outputs the new representation <span class="math notranslate nohighlight">\(h_i^{k+1}\)</span> of node <span class="math notranslate nohighlight">\(i\)</span>. The aggregation function can be a simple sum-, mean-, or max-operation. However, it can also be implemented by an arbitrary neural layer type as e.g. a fully connected layer or a recurrent layer.</p></li>
</ol>
<p>This process is performed, in parallel, on all nodes <span class="math notranslate nohighlight">\(i\)</span> in the graph as node-embeddings in iteration <span class="math notranslate nohighlight">\(k+1\)</span> depend on embeddings in iteration <span class="math notranslate nohighlight">\(k\)</span>. In this way in each iteration each node <em>grabs</em> more information from it’s surrounding nodes. Finally this <em>better representations</em> can be applied for different tasks, such as node-classification, node-clustering, sub-graph-identification, sub-graph-clustering etc. Depending on the task, individual node embeddings of type <span class="math notranslate nohighlight">\(h_i^{k}\)</span>, or representations of sub-graphs or the entire graph may be required. A simple representation of a subgraph or graph can be obtained by just summing up the node-embeddings of all nodes in the graph or subgraph, respectively.</p>
<figure align="center">
<img src="https://maucher.home.hdm-stuttgart.de/Pics/graphMessagePassing.png" width="800px" align="center">
<figcaption>
Figure 3: Calculation of new descriptor at node 0.
</figcaption>
</figure></div>
<div class="section" id="graph-convolutional-network-gcn">
<h3>Graph Convolutional Network (GCN)<a class="headerlink" href="#graph-convolutional-network-gcn" title="Permalink to this headline">¶</a></h3>
<p>Next, we will consider how the concept of message passing, as introduced in the previous subsection, is implemented in Graph Neural Networks (GNNs)?</p>
<p>As explained in the previous subsections, in each iteration each node’s descriptor vector is updated by the messages from the neighbouring nodes. In a Graph Convolutional Network (GCN) each iteration is implemented by a GCN-layer. I.e. the first update is calculated in the first GCN-layer, the second update is calculated in the second layer and so on. Thus the number of updates and therefore the range of the neighbourhood that is considered in the final node representation is given by the number of GCN layers. Such a stack of GCN-layers is depicted in the right hand side of Figure 4. In this Figure the abbreviation GNN is used for Graph Neural Net (GNN). GNN is more general as GCN, but here we always assume that the GNN is a GCN. The short-cut connections around the GNN layers are necessary, because the new representation of a node is the aggregation of the messages from the neighboring nodes and the old representation of this node.</p>
<p>As depicted in the right hand side of Figure 4, the stack of GCN layers is preceeded by one or more preprocessing layers, which calculate the initial node descriptors. The initial node descriptors do not depend on the neighbouring codes. Moreover, the output of the GCN-layer stack is passed to one or more post-processing layers. These post-processing layers depend on the task. E.g. for the task of node-classification, the post-processing layers assign to each node descriptor at the output of the GCN-layer stack the category of the node.</p>
<p>In Figure 3, it was assumed, that the message <span class="math notranslate nohighlight">\(m_u^k\)</span> coming from node <span class="math notranslate nohighlight">\(u\)</span> in iteration <span class="math notranslate nohighlight">\(k+1\)</span> is the output of a dense layer (linear layer), whose input is the node descriptor <span class="math notranslate nohighlight">\(h_u^k\)</span>. In general, as depicted in the left hand-side of the image below, the dense layer can apply Batch-Normalization, Dropout and an arbitrary Activation function.</p>
<figure align="center">
<img src="https://maucher.home.hdm-stuttgart.de/Pics/GNNDesign.png" width="600px" align="center">
<figcaption>
Figure 4: Image Source: <a href="https://arxiv.org/abs/2011.08843">Design Space for Graph Neural Networks</a> 
</figcaption>
</figure>
<p>Where does the name <em>Graph Convolutional Layer</em> come from?</p>
<p>For this take a look to the left hand side of Figure 5. In a <em>Convolutional Layer</em> at each position a new value is calculated as the scalar-product of the filter coefficients and the receptive field of the current position (neuron). Each position (neuron) can be considered as a node. And each node has an edge to all other nodes (positions), which belong to the local receptive field of the current position (neuron). Actually, at each position not only one value is calculated, but one value for each feature map.</p>
<p>With this notion in mind, the difference of a graph convolution layer w.r.t. a convolution layer is that in a GCN each node can have an arbitrary number of neighbouring nodes, whereas in a convolution layer the number of neighbouring nodes is fixed and given by the size of the filter.</p>
<figure align="center">
<img src="https://maucher.home.hdm-stuttgart.de/Pics/gcnVScnn.png" width="600px" align="center">
<figcaption>
    Figure 5: Image Source: <a href="https://arxiv.org/pdf/1901.00596.pdf">Wu et al.: A Comprehensive Survey on Graph Neural Networks</a>
</figcaption>
</figure>
</div>
<div class="section" id="graph-convolutional-network-for-node-classification">
<h3>Graph Convolutional Network for Node Classification<a class="headerlink" href="#graph-convolutional-network-for-node-classification" title="Permalink to this headline">¶</a></h3>
<figure align="center">
<img src="https://maucher.home.hdm-stuttgart.de/Pics/gcnNodeClassification.png" width="600px" align="center">
<figcaption>
    Image Source: <a href="https://arxiv.org/pdf/1901.00596.pdf">Wu et al.: A Comprehensive Survey on Graph Neural Networks</a>
</figcaption>
</figure>
</div>
<div class="section" id="graph-convolutional-network-for-graph-classification">
<h3>Graph Convolutional Network for Graph Classification<a class="headerlink" href="#graph-convolutional-network-for-graph-classification" title="Permalink to this headline">¶</a></h3>
<figure align="center">
<img src="https://maucher.home.hdm-stuttgart.de/Pics/gcnGraphClassification.png" width="600px"align="center">
<figcaption>
    Image Source: <a href="https://arxiv.org/pdf/1901.00596.pdf">Wu et al.: A Comprehensive Survey on Graph Neural Networks</a>
</figcaption>
</figure>
<p><a id='intro'></a></p>
</div>
</div>
</div>
<div class="section" id="introductory-example-node-classification-with-graph-neural-networks">
<h1>Introductory Example: Node Classification with Graph Neural Networks<a class="headerlink" href="#introductory-example-node-classification-with-graph-neural-networks" title="Permalink to this headline">¶</a></h1>
<p>After learning the basic concepts of Graph Neural Networks, we continue with the implementation of Graph Convolution Networks (GCN). This part is an adaptation of the <a class="reference external" href="https://keras.io/examples/graph/gnn_citations/">Keras tutorial</a>. You don’t have to implement the GCN layer and the GCN Network by yourself, but you should study this part carefully, such that you are able</p>
<ul class="simple">
<li><p>to answer the questions at the end of this section</p></li>
<li><p>to implement the GCN network on the task of music genre prediction in the following section.</p></li>
</ul>
<div class="section" id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">¶</a></h2>
<p>This example demonstrates a simple implementation of a <a class="reference external" href="https://arxiv.org/pdf/1901.00596.pdf">Graph Neural Network</a>
(GNN) model. The model is used for a node prediction task on the <a class="reference external" href="https://relational.fit.cvut.cz/dataset/CORA">Cora dataset</a>
to predict the subject of a paper given its words and citations network.</p>
<p>Note that, <strong>we implement a Graph Convolution Layer from scratch</strong> to provide a better
understanding of how they work. However, there is a number of specialized TensorFlow-based
libraries that provide rich GNN APIs, such as <a class="reference external" href="https://graphneural.network/">Spectral</a>,
<a class="reference external" href="https://stellargraph.readthedocs.io/en/stable/README.html">StellarGraph</a>, and
<a class="reference external" href="https://github.com/deepmind/graph_nets">GraphNets</a>.</p>
</div>
<div class="section" id="setup">
<h2>Setup<a class="headerlink" href="#setup" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">networkx</span> <span class="k">as</span> <span class="nn">nx</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow</span> <span class="kn">import</span> <span class="n">keras</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">layers</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">set_printoptions</span><span class="p">(</span><span class="n">suppress</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="prepare-the-dataset">
<h2>Prepare the Dataset<a class="headerlink" href="#prepare-the-dataset" title="Permalink to this headline">¶</a></h2>
<p>The Cora dataset consists of 2,708 scientific papers classified into one of seven classes.
The citation network consists of 5,429 links. Each paper has a binary word vector of size
1,433, indicating the presence of a corresponding word.</p>
<div class="section" id="download-the-dataset">
<h3>Download the dataset<a class="headerlink" href="#download-the-dataset" title="Permalink to this headline">¶</a></h3>
<p>The dataset has two tap-separated files: <code class="docutils literal notranslate"><span class="pre">cora.cites</span></code> and <code class="docutils literal notranslate"><span class="pre">cora.content</span></code>.</p>
<ol class="simple">
<li><p>The <code class="docutils literal notranslate"><span class="pre">cora.cites</span></code> includes the citation records with two columns:
<code class="docutils literal notranslate"><span class="pre">cited_paper_id</span></code> (target) and <code class="docutils literal notranslate"><span class="pre">citing_paper_id</span></code> (source).</p></li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">cora.content</span></code> includes the paper content records with 1,435 columns:
<code class="docutils literal notranslate"><span class="pre">paper_id</span></code>, <code class="docutils literal notranslate"><span class="pre">subject</span></code>, and 1,433 binary features.</p></li>
</ol>
<p>First the Cora-dataset is downloaded and extracted:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">zip_file</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">get_file</span><span class="p">(</span>
    <span class="n">fname</span><span class="o">=</span><span class="s2">&quot;cora.tgz&quot;</span><span class="p">,</span>
    <span class="n">origin</span><span class="o">=</span><span class="s2">&quot;https://linqs-data.soe.ucsc.edu/public/lbc/cora.tgz&quot;</span><span class="p">,</span>
    <span class="n">extract</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">data_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">zip_file</span><span class="p">),</span> <span class="s2">&quot;cora&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">zip_file</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&#39;/Users/johannes/.keras/datasets/cora.tgz&#39;
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="process-and-visualize-the-dataset">
<h3>Process and visualize the dataset<a class="headerlink" href="#process-and-visualize-the-dataset" title="Permalink to this headline">¶</a></h3>
<p>Then we load the citations data into a Pandas DataFrame.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">citations</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span>
    <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="s2">&quot;cora.cites&quot;</span><span class="p">),</span>
    <span class="n">sep</span><span class="o">=</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">&quot;</span><span class="p">,</span>
    <span class="n">header</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;target&quot;</span><span class="p">,</span> <span class="s2">&quot;source&quot;</span><span class="p">],</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Citations shape:&quot;</span><span class="p">,</span> <span class="n">citations</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Citations shape: (5429, 2)
</pre></div>
</div>
</div>
</div>
<p>Now we display a sample of the <code class="docutils literal notranslate"><span class="pre">citations</span></code> DataFrame.
The <code class="docutils literal notranslate"><span class="pre">target</span></code> column includes the paper ids cited by the paper ids in the <code class="docutils literal notranslate"><span class="pre">source</span></code> column.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">citations</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>target</th>
      <th>source</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>35</td>
      <td>1033</td>
    </tr>
    <tr>
      <th>1</th>
      <td>35</td>
      <td>103482</td>
    </tr>
    <tr>
      <th>2</th>
      <td>35</td>
      <td>103515</td>
    </tr>
    <tr>
      <th>3</th>
      <td>35</td>
      <td>1050679</td>
    </tr>
    <tr>
      <th>4</th>
      <td>35</td>
      <td>1103960</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>As can be seen in the output of the next-code cell, there are some papers (e.g. paper 35), which are referenced by many others. Other papers are referenced only once or even not at all.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">citations</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>35        166
6213       76
1365       74
3229       61
114        42
         ... 
136766      1
136768      1
137956      1
139738      1
954315      1
Name: target, Length: 1565, dtype: int64
</pre></div>
</div>
</div>
</div>
<p>Now let’s load the papers data into a Pandas DataFrame.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">column_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;paper_id&quot;</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;term_</span><span class="si">{</span><span class="n">idx</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1433</span><span class="p">)]</span> <span class="o">+</span> <span class="p">[</span><span class="s2">&quot;subject&quot;</span><span class="p">]</span>
<span class="n">papers</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span>
    <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="s2">&quot;cora.content&quot;</span><span class="p">),</span> <span class="n">sep</span><span class="o">=</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">names</span><span class="o">=</span><span class="n">column_names</span><span class="p">,</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Papers shape:&quot;</span><span class="p">,</span> <span class="n">papers</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Papers shape: (2708, 1435)
</pre></div>
</div>
</div>
</div>
<p>Now we display a sample of the <code class="docutils literal notranslate"><span class="pre">papers</span></code> DataFrame. The DataFrame includes the <code class="docutils literal notranslate"><span class="pre">paper_id</span></code>
and the <code class="docutils literal notranslate"><span class="pre">subject</span></code> columns, as well as 1,433 binary column representing whether a term exists
in the paper or not.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">papers</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>paper_id</th>
      <th>term_0</th>
      <th>term_1</th>
      <th>term_2</th>
      <th>term_3</th>
      <th>term_4</th>
      <th>term_5</th>
      <th>term_6</th>
      <th>term_7</th>
      <th>term_8</th>
      <th>...</th>
      <th>term_1424</th>
      <th>term_1425</th>
      <th>term_1426</th>
      <th>term_1427</th>
      <th>term_1428</th>
      <th>term_1429</th>
      <th>term_1430</th>
      <th>term_1431</th>
      <th>term_1432</th>
      <th>subject</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>31336</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>Neural_Networks</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1061127</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>Rule_Learning</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1106406</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>Reinforcement_Learning</td>
    </tr>
    <tr>
      <th>3</th>
      <td>13195</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>Reinforcement_Learning</td>
    </tr>
    <tr>
      <th>4</th>
      <td>37879</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>Probabilistic_Methods</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 1435 columns</p>
</div></div></div>
</div>
<p>Let’s display the count of the papers in each subject.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">papers</span><span class="o">.</span><span class="n">subject</span><span class="o">.</span><span class="n">value_counts</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Neural_Networks           818
Probabilistic_Methods     426
Genetic_Algorithms        418
Theory                    351
Case_Based                298
Reinforcement_Learning    217
Rule_Learning             180
Name: subject, dtype: int64
</pre></div>
</div>
</div>
</div>
<p>We convert the paper ids and the subjects into zero-based indices.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">class_values</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">papers</span><span class="p">[</span><span class="s2">&quot;subject&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">())</span>
<span class="n">class_idx</span> <span class="o">=</span> <span class="p">{</span><span class="n">name</span><span class="p">:</span> <span class="nb">id</span> <span class="k">for</span> <span class="nb">id</span><span class="p">,</span> <span class="n">name</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">class_values</span><span class="p">)}</span>
<span class="n">paper_idx</span> <span class="o">=</span> <span class="p">{</span><span class="n">name</span><span class="p">:</span> <span class="n">idx</span> <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">name</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">sorted</span><span class="p">(</span><span class="n">papers</span><span class="p">[</span><span class="s2">&quot;paper_id&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">()))}</span>

<span class="n">papers</span><span class="p">[</span><span class="s2">&quot;paper_id&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">papers</span><span class="p">[</span><span class="s2">&quot;paper_id&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">name</span><span class="p">:</span> <span class="n">paper_idx</span><span class="p">[</span><span class="n">name</span><span class="p">])</span>
<span class="n">citations</span><span class="p">[</span><span class="s2">&quot;source&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">citations</span><span class="p">[</span><span class="s2">&quot;source&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">name</span><span class="p">:</span> <span class="n">paper_idx</span><span class="p">[</span><span class="n">name</span><span class="p">])</span>
<span class="n">citations</span><span class="p">[</span><span class="s2">&quot;target&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">citations</span><span class="p">[</span><span class="s2">&quot;target&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">name</span><span class="p">:</span> <span class="n">paper_idx</span><span class="p">[</span><span class="n">name</span><span class="p">])</span>
<span class="n">papers</span><span class="p">[</span><span class="s2">&quot;subject&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">papers</span><span class="p">[</span><span class="s2">&quot;subject&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">value</span><span class="p">:</span> <span class="n">class_idx</span><span class="p">[</span><span class="n">value</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">class_values</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">papers</span><span class="p">[</span><span class="s2">&quot;subject&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">())</span>
<span class="n">class_idx</span> <span class="o">=</span> <span class="p">{</span><span class="n">name</span><span class="p">:</span> <span class="nb">id</span> <span class="k">for</span> <span class="nb">id</span><span class="p">,</span> <span class="n">name</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">class_values</span><span class="p">)}</span>
<span class="n">paper_idx</span> <span class="o">=</span> <span class="p">{</span><span class="n">name</span><span class="p">:</span> <span class="n">idx</span> <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">name</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">sorted</span><span class="p">(</span><span class="n">papers</span><span class="p">[</span><span class="s2">&quot;paper_id&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">()))}</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">class_idx</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6}
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">paper_idx</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{0: 0,
 1: 1,
 2: 2,
 3: 3,
 4: 4,
 5: 5,
 6: 6,
 7: 7,
 8: 8,
 9: 9,
 10: 10,
 11: 11,
 12: 12,
 13: 13,
 14: 14,
 15: 15,
 16: 16,
 17: 17,
 18: 18,
 19: 19,
 20: 20,
 21: 21,
 22: 22,
 23: 23,
 24: 24,
 25: 25,
 26: 26,
 27: 27,
 28: 28,
 29: 29,
 30: 30,
 31: 31,
 32: 32,
 33: 33,
 34: 34,
 35: 35,
 36: 36,
 37: 37,
 38: 38,
 39: 39,
 40: 40,
 41: 41,
 42: 42,
 43: 43,
 44: 44,
 45: 45,
 46: 46,
 47: 47,
 48: 48,
 49: 49,
 50: 50,
 51: 51,
 52: 52,
 53: 53,
 54: 54,
 55: 55,
 56: 56,
 57: 57,
 58: 58,
 59: 59,
 60: 60,
 61: 61,
 62: 62,
 63: 63,
 64: 64,
 65: 65,
 66: 66,
 67: 67,
 68: 68,
 69: 69,
 70: 70,
 71: 71,
 72: 72,
 73: 73,
 74: 74,
 75: 75,
 76: 76,
 77: 77,
 78: 78,
 79: 79,
 80: 80,
 81: 81,
 82: 82,
 83: 83,
 84: 84,
 85: 85,
 86: 86,
 87: 87,
 88: 88,
 89: 89,
 90: 90,
 91: 91,
 92: 92,
 93: 93,
 94: 94,
 95: 95,
 96: 96,
 97: 97,
 98: 98,
 99: 99,
 100: 100,
 101: 101,
 102: 102,
 103: 103,
 104: 104,
 105: 105,
 106: 106,
 107: 107,
 108: 108,
 109: 109,
 110: 110,
 111: 111,
 112: 112,
 113: 113,
 114: 114,
 115: 115,
 116: 116,
 117: 117,
 118: 118,
 119: 119,
 120: 120,
 121: 121,
 122: 122,
 123: 123,
 124: 124,
 125: 125,
 126: 126,
 127: 127,
 128: 128,
 129: 129,
 130: 130,
 131: 131,
 132: 132,
 133: 133,
 134: 134,
 135: 135,
 136: 136,
 137: 137,
 138: 138,
 139: 139,
 140: 140,
 141: 141,
 142: 142,
 143: 143,
 144: 144,
 145: 145,
 146: 146,
 147: 147,
 148: 148,
 149: 149,
 150: 150,
 151: 151,
 152: 152,
 153: 153,
 154: 154,
 155: 155,
 156: 156,
 157: 157,
 158: 158,
 159: 159,
 160: 160,
 161: 161,
 162: 162,
 163: 163,
 164: 164,
 165: 165,
 166: 166,
 167: 167,
 168: 168,
 169: 169,
 170: 170,
 171: 171,
 172: 172,
 173: 173,
 174: 174,
 175: 175,
 176: 176,
 177: 177,
 178: 178,
 179: 179,
 180: 180,
 181: 181,
 182: 182,
 183: 183,
 184: 184,
 185: 185,
 186: 186,
 187: 187,
 188: 188,
 189: 189,
 190: 190,
 191: 191,
 192: 192,
 193: 193,
 194: 194,
 195: 195,
 196: 196,
 197: 197,
 198: 198,
 199: 199,
 200: 200,
 201: 201,
 202: 202,
 203: 203,
 204: 204,
 205: 205,
 206: 206,
 207: 207,
 208: 208,
 209: 209,
 210: 210,
 211: 211,
 212: 212,
 213: 213,
 214: 214,
 215: 215,
 216: 216,
 217: 217,
 218: 218,
 219: 219,
 220: 220,
 221: 221,
 222: 222,
 223: 223,
 224: 224,
 225: 225,
 226: 226,
 227: 227,
 228: 228,
 229: 229,
 230: 230,
 231: 231,
 232: 232,
 233: 233,
 234: 234,
 235: 235,
 236: 236,
 237: 237,
 238: 238,
 239: 239,
 240: 240,
 241: 241,
 242: 242,
 243: 243,
 244: 244,
 245: 245,
 246: 246,
 247: 247,
 248: 248,
 249: 249,
 250: 250,
 251: 251,
 252: 252,
 253: 253,
 254: 254,
 255: 255,
 256: 256,
 257: 257,
 258: 258,
 259: 259,
 260: 260,
 261: 261,
 262: 262,
 263: 263,
 264: 264,
 265: 265,
 266: 266,
 267: 267,
 268: 268,
 269: 269,
 270: 270,
 271: 271,
 272: 272,
 273: 273,
 274: 274,
 275: 275,
 276: 276,
 277: 277,
 278: 278,
 279: 279,
 280: 280,
 281: 281,
 282: 282,
 283: 283,
 284: 284,
 285: 285,
 286: 286,
 287: 287,
 288: 288,
 289: 289,
 290: 290,
 291: 291,
 292: 292,
 293: 293,
 294: 294,
 295: 295,
 296: 296,
 297: 297,
 298: 298,
 299: 299,
 300: 300,
 301: 301,
 302: 302,
 303: 303,
 304: 304,
 305: 305,
 306: 306,
 307: 307,
 308: 308,
 309: 309,
 310: 310,
 311: 311,
 312: 312,
 313: 313,
 314: 314,
 315: 315,
 316: 316,
 317: 317,
 318: 318,
 319: 319,
 320: 320,
 321: 321,
 322: 322,
 323: 323,
 324: 324,
 325: 325,
 326: 326,
 327: 327,
 328: 328,
 329: 329,
 330: 330,
 331: 331,
 332: 332,
 333: 333,
 334: 334,
 335: 335,
 336: 336,
 337: 337,
 338: 338,
 339: 339,
 340: 340,
 341: 341,
 342: 342,
 343: 343,
 344: 344,
 345: 345,
 346: 346,
 347: 347,
 348: 348,
 349: 349,
 350: 350,
 351: 351,
 352: 352,
 353: 353,
 354: 354,
 355: 355,
 356: 356,
 357: 357,
 358: 358,
 359: 359,
 360: 360,
 361: 361,
 362: 362,
 363: 363,
 364: 364,
 365: 365,
 366: 366,
 367: 367,
 368: 368,
 369: 369,
 370: 370,
 371: 371,
 372: 372,
 373: 373,
 374: 374,
 375: 375,
 376: 376,
 377: 377,
 378: 378,
 379: 379,
 380: 380,
 381: 381,
 382: 382,
 383: 383,
 384: 384,
 385: 385,
 386: 386,
 387: 387,
 388: 388,
 389: 389,
 390: 390,
 391: 391,
 392: 392,
 393: 393,
 394: 394,
 395: 395,
 396: 396,
 397: 397,
 398: 398,
 399: 399,
 400: 400,
 401: 401,
 402: 402,
 403: 403,
 404: 404,
 405: 405,
 406: 406,
 407: 407,
 408: 408,
 409: 409,
 410: 410,
 411: 411,
 412: 412,
 413: 413,
 414: 414,
 415: 415,
 416: 416,
 417: 417,
 418: 418,
 419: 419,
 420: 420,
 421: 421,
 422: 422,
 423: 423,
 424: 424,
 425: 425,
 426: 426,
 427: 427,
 428: 428,
 429: 429,
 430: 430,
 431: 431,
 432: 432,
 433: 433,
 434: 434,
 435: 435,
 436: 436,
 437: 437,
 438: 438,
 439: 439,
 440: 440,
 441: 441,
 442: 442,
 443: 443,
 444: 444,
 445: 445,
 446: 446,
 447: 447,
 448: 448,
 449: 449,
 450: 450,
 451: 451,
 452: 452,
 453: 453,
 454: 454,
 455: 455,
 456: 456,
 457: 457,
 458: 458,
 459: 459,
 460: 460,
 461: 461,
 462: 462,
 463: 463,
 464: 464,
 465: 465,
 466: 466,
 467: 467,
 468: 468,
 469: 469,
 470: 470,
 471: 471,
 472: 472,
 473: 473,
 474: 474,
 475: 475,
 476: 476,
 477: 477,
 478: 478,
 479: 479,
 480: 480,
 481: 481,
 482: 482,
 483: 483,
 484: 484,
 485: 485,
 486: 486,
 487: 487,
 488: 488,
 489: 489,
 490: 490,
 491: 491,
 492: 492,
 493: 493,
 494: 494,
 495: 495,
 496: 496,
 497: 497,
 498: 498,
 499: 499,
 500: 500,
 501: 501,
 502: 502,
 503: 503,
 504: 504,
 505: 505,
 506: 506,
 507: 507,
 508: 508,
 509: 509,
 510: 510,
 511: 511,
 512: 512,
 513: 513,
 514: 514,
 515: 515,
 516: 516,
 517: 517,
 518: 518,
 519: 519,
 520: 520,
 521: 521,
 522: 522,
 523: 523,
 524: 524,
 525: 525,
 526: 526,
 527: 527,
 528: 528,
 529: 529,
 530: 530,
 531: 531,
 532: 532,
 533: 533,
 534: 534,
 535: 535,
 536: 536,
 537: 537,
 538: 538,
 539: 539,
 540: 540,
 541: 541,
 542: 542,
 543: 543,
 544: 544,
 545: 545,
 546: 546,
 547: 547,
 548: 548,
 549: 549,
 550: 550,
 551: 551,
 552: 552,
 553: 553,
 554: 554,
 555: 555,
 556: 556,
 557: 557,
 558: 558,
 559: 559,
 560: 560,
 561: 561,
 562: 562,
 563: 563,
 564: 564,
 565: 565,
 566: 566,
 567: 567,
 568: 568,
 569: 569,
 570: 570,
 571: 571,
 572: 572,
 573: 573,
 574: 574,
 575: 575,
 576: 576,
 577: 577,
 578: 578,
 579: 579,
 580: 580,
 581: 581,
 582: 582,
 583: 583,
 584: 584,
 585: 585,
 586: 586,
 587: 587,
 588: 588,
 589: 589,
 590: 590,
 591: 591,
 592: 592,
 593: 593,
 594: 594,
 595: 595,
 596: 596,
 597: 597,
 598: 598,
 599: 599,
 600: 600,
 601: 601,
 602: 602,
 603: 603,
 604: 604,
 605: 605,
 606: 606,
 607: 607,
 608: 608,
 609: 609,
 610: 610,
 611: 611,
 612: 612,
 613: 613,
 614: 614,
 615: 615,
 616: 616,
 617: 617,
 618: 618,
 619: 619,
 620: 620,
 621: 621,
 622: 622,
 623: 623,
 624: 624,
 625: 625,
 626: 626,
 627: 627,
 628: 628,
 629: 629,
 630: 630,
 631: 631,
 632: 632,
 633: 633,
 634: 634,
 635: 635,
 636: 636,
 637: 637,
 638: 638,
 639: 639,
 640: 640,
 641: 641,
 642: 642,
 643: 643,
 644: 644,
 645: 645,
 646: 646,
 647: 647,
 648: 648,
 649: 649,
 650: 650,
 651: 651,
 652: 652,
 653: 653,
 654: 654,
 655: 655,
 656: 656,
 657: 657,
 658: 658,
 659: 659,
 660: 660,
 661: 661,
 662: 662,
 663: 663,
 664: 664,
 665: 665,
 666: 666,
 667: 667,
 668: 668,
 669: 669,
 670: 670,
 671: 671,
 672: 672,
 673: 673,
 674: 674,
 675: 675,
 676: 676,
 677: 677,
 678: 678,
 679: 679,
 680: 680,
 681: 681,
 682: 682,
 683: 683,
 684: 684,
 685: 685,
 686: 686,
 687: 687,
 688: 688,
 689: 689,
 690: 690,
 691: 691,
 692: 692,
 693: 693,
 694: 694,
 695: 695,
 696: 696,
 697: 697,
 698: 698,
 699: 699,
 700: 700,
 701: 701,
 702: 702,
 703: 703,
 704: 704,
 705: 705,
 706: 706,
 707: 707,
 708: 708,
 709: 709,
 710: 710,
 711: 711,
 712: 712,
 713: 713,
 714: 714,
 715: 715,
 716: 716,
 717: 717,
 718: 718,
 719: 719,
 720: 720,
 721: 721,
 722: 722,
 723: 723,
 724: 724,
 725: 725,
 726: 726,
 727: 727,
 728: 728,
 729: 729,
 730: 730,
 731: 731,
 732: 732,
 733: 733,
 734: 734,
 735: 735,
 736: 736,
 737: 737,
 738: 738,
 739: 739,
 740: 740,
 741: 741,
 742: 742,
 743: 743,
 744: 744,
 745: 745,
 746: 746,
 747: 747,
 748: 748,
 749: 749,
 750: 750,
 751: 751,
 752: 752,
 753: 753,
 754: 754,
 755: 755,
 756: 756,
 757: 757,
 758: 758,
 759: 759,
 760: 760,
 761: 761,
 762: 762,
 763: 763,
 764: 764,
 765: 765,
 766: 766,
 767: 767,
 768: 768,
 769: 769,
 770: 770,
 771: 771,
 772: 772,
 773: 773,
 774: 774,
 775: 775,
 776: 776,
 777: 777,
 778: 778,
 779: 779,
 780: 780,
 781: 781,
 782: 782,
 783: 783,
 784: 784,
 785: 785,
 786: 786,
 787: 787,
 788: 788,
 789: 789,
 790: 790,
 791: 791,
 792: 792,
 793: 793,
 794: 794,
 795: 795,
 796: 796,
 797: 797,
 798: 798,
 799: 799,
 800: 800,
 801: 801,
 802: 802,
 803: 803,
 804: 804,
 805: 805,
 806: 806,
 807: 807,
 808: 808,
 809: 809,
 810: 810,
 811: 811,
 812: 812,
 813: 813,
 814: 814,
 815: 815,
 816: 816,
 817: 817,
 818: 818,
 819: 819,
 820: 820,
 821: 821,
 822: 822,
 823: 823,
 824: 824,
 825: 825,
 826: 826,
 827: 827,
 828: 828,
 829: 829,
 830: 830,
 831: 831,
 832: 832,
 833: 833,
 834: 834,
 835: 835,
 836: 836,
 837: 837,
 838: 838,
 839: 839,
 840: 840,
 841: 841,
 842: 842,
 843: 843,
 844: 844,
 845: 845,
 846: 846,
 847: 847,
 848: 848,
 849: 849,
 850: 850,
 851: 851,
 852: 852,
 853: 853,
 854: 854,
 855: 855,
 856: 856,
 857: 857,
 858: 858,
 859: 859,
 860: 860,
 861: 861,
 862: 862,
 863: 863,
 864: 864,
 865: 865,
 866: 866,
 867: 867,
 868: 868,
 869: 869,
 870: 870,
 871: 871,
 872: 872,
 873: 873,
 874: 874,
 875: 875,
 876: 876,
 877: 877,
 878: 878,
 879: 879,
 880: 880,
 881: 881,
 882: 882,
 883: 883,
 884: 884,
 885: 885,
 886: 886,
 887: 887,
 888: 888,
 889: 889,
 890: 890,
 891: 891,
 892: 892,
 893: 893,
 894: 894,
 895: 895,
 896: 896,
 897: 897,
 898: 898,
 899: 899,
 900: 900,
 901: 901,
 902: 902,
 903: 903,
 904: 904,
 905: 905,
 906: 906,
 907: 907,
 908: 908,
 909: 909,
 910: 910,
 911: 911,
 912: 912,
 913: 913,
 914: 914,
 915: 915,
 916: 916,
 917: 917,
 918: 918,
 919: 919,
 920: 920,
 921: 921,
 922: 922,
 923: 923,
 924: 924,
 925: 925,
 926: 926,
 927: 927,
 928: 928,
 929: 929,
 930: 930,
 931: 931,
 932: 932,
 933: 933,
 934: 934,
 935: 935,
 936: 936,
 937: 937,
 938: 938,
 939: 939,
 940: 940,
 941: 941,
 942: 942,
 943: 943,
 944: 944,
 945: 945,
 946: 946,
 947: 947,
 948: 948,
 949: 949,
 950: 950,
 951: 951,
 952: 952,
 953: 953,
 954: 954,
 955: 955,
 956: 956,
 957: 957,
 958: 958,
 959: 959,
 960: 960,
 961: 961,
 962: 962,
 963: 963,
 964: 964,
 965: 965,
 966: 966,
 967: 967,
 968: 968,
 969: 969,
 970: 970,
 971: 971,
 972: 972,
 973: 973,
 974: 974,
 975: 975,
 976: 976,
 977: 977,
 978: 978,
 979: 979,
 980: 980,
 981: 981,
 982: 982,
 983: 983,
 984: 984,
 985: 985,
 986: 986,
 987: 987,
 988: 988,
 989: 989,
 990: 990,
 991: 991,
 992: 992,
 993: 993,
 994: 994,
 995: 995,
 996: 996,
 997: 997,
 998: 998,
 999: 999,
 ...}
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">papers</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(2708, 1435)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">citations</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>target</th>
      <th>source</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>21</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0</td>
      <td>905</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0</td>
      <td>906</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0</td>
      <td>1909</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>1940</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Now let’s visualize the citation graph. Each node in the graph represents a paper,
and the color of the node corresponds to its subject. Note that we only show a sample of
the papers in the dataset.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="n">colors</span> <span class="o">=</span> <span class="n">papers</span><span class="p">[</span><span class="s2">&quot;subject&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
<span class="n">cora_graph</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">from_pandas_edgelist</span><span class="p">(</span><span class="n">citations</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">1500</span><span class="p">))</span>
<span class="n">subjects</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">papers</span><span class="p">[</span><span class="n">papers</span><span class="p">[</span><span class="s2">&quot;paper_id&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">cora_graph</span><span class="o">.</span><span class="n">nodes</span><span class="p">))][</span><span class="s2">&quot;subject&quot;</span><span class="p">])</span>
<span class="n">nx</span><span class="o">.</span><span class="n">draw_spring</span><span class="p">(</span><span class="n">cora_graph</span><span class="p">,</span> <span class="n">node_size</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">node_color</span><span class="o">=</span><span class="n">subjects</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/GraphNeuralNetworks_34_0.png" src="../_images/GraphNeuralNetworks_34_0.png" />
</div>
</div>
</div>
<div class="section" id="split-the-dataset-into-stratified-train-and-test-sets">
<h3>Split the dataset into stratified train and test sets<a class="headerlink" href="#split-the-dataset-into-stratified-train-and-test-sets" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_data</span><span class="p">,</span> <span class="n">test_data</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">group_data</span> <span class="ow">in</span> <span class="n">papers</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s2">&quot;subject&quot;</span><span class="p">):</span>
    <span class="c1"># Select around 85% of the dataset for training and validation, and 15% for test</span>
    <span class="n">random_selection</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">group_data</span><span class="o">.</span><span class="n">index</span><span class="p">))</span> <span class="o">&lt;=</span> <span class="mf">0.5</span>
    <span class="n">train_data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">group_data</span><span class="p">[</span><span class="n">random_selection</span><span class="p">])</span>
    <span class="n">test_data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">group_data</span><span class="p">[</span><span class="o">~</span><span class="n">random_selection</span><span class="p">])</span>

<span class="n">train_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">train_data</span><span class="p">)</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">frac</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">test_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">frac</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Train data shape:&quot;</span><span class="p">,</span> <span class="n">train_data</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test data shape:&quot;</span><span class="p">,</span> <span class="n">test_data</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Train data shape: (1369, 1435)
Test data shape: (1339, 1435)
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="implement-train-and-evaluate-experiment">
<h2>Implement, Train and Evaluate Experiment<a class="headerlink" href="#implement-train-and-evaluate-experiment" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">hidden_units</span> <span class="o">=</span> <span class="p">[</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">]</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.01</span>
<span class="n">dropout_rate</span> <span class="o">=</span> <span class="mf">0.5</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">300</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">256</span>
</pre></div>
</div>
</div>
</div>
<p>This function compiles and trains an input model using the given training data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">run_experiment</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">):</span>
    <span class="c1"># Compile the model.</span>
    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
        <span class="n">optimizer</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="p">),</span>
        <span class="n">loss</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">SparseCategoricalCrossentropy</span><span class="p">(</span><span class="n">from_logits</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
        <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">SparseCategoricalAccuracy</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;acc&quot;</span><span class="p">)],</span>
    <span class="p">)</span>
    <span class="c1"># Create an early stopping callback.</span>
    <span class="n">early_stopping</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">EarlyStopping</span><span class="p">(</span>
        <span class="n">monitor</span><span class="o">=</span><span class="s2">&quot;val_acc&quot;</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">restore_best_weights</span><span class="o">=</span><span class="kc">True</span>
    <span class="p">)</span>
    <span class="c1"># Fit the model.</span>
    <span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
        <span class="n">x</span><span class="o">=</span><span class="n">x_train</span><span class="p">,</span>
        <span class="n">y</span><span class="o">=</span><span class="n">y_train</span><span class="p">,</span>
        <span class="n">epochs</span><span class="o">=</span><span class="n">num_epochs</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
        <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span>
        <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">early_stopping</span><span class="p">],</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">history</span>
</pre></div>
</div>
</div>
</div>
<p>This function displays the loss and accuracy curves of the model during training.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">display_learning_curves</span><span class="p">(</span><span class="n">history</span><span class="p">):</span>
    <span class="n">fig</span><span class="p">,</span> <span class="p">(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

    <span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s2">&quot;loss&quot;</span><span class="p">])</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s2">&quot;val_loss&quot;</span><span class="p">])</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s2">&quot;train&quot;</span><span class="p">,</span> <span class="s2">&quot;test&quot;</span><span class="p">],</span> <span class="n">loc</span><span class="o">=</span><span class="s2">&quot;upper right&quot;</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Epochs&quot;</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Loss&quot;</span><span class="p">)</span>

    <span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s2">&quot;acc&quot;</span><span class="p">])</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s2">&quot;val_acc&quot;</span><span class="p">])</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s2">&quot;train&quot;</span><span class="p">,</span> <span class="s2">&quot;test&quot;</span><span class="p">],</span> <span class="n">loc</span><span class="o">=</span><span class="s2">&quot;upper right&quot;</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Epochs&quot;</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Accuracy&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="implement-feedforward-network-ffn-module">
<h2>Implement Feedforward Network (FFN) Module<a class="headerlink" href="#implement-feedforward-network-ffn-module" title="Permalink to this headline">¶</a></h2>
<p>We will use this module in the baseline and the GNN models.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">create_ffn</span><span class="p">(</span><span class="n">hidden_units</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">fnn_layers</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">units</span> <span class="ow">in</span> <span class="n">hidden_units</span><span class="p">:</span>
        <span class="n">fnn_layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">())</span>
        <span class="n">fnn_layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_rate</span><span class="p">))</span>
        <span class="n">fnn_layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">units</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">gelu</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">fnn_layers</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="build-a-baseline-neural-network-model">
<h2>Build a Baseline Neural Network Model<a class="headerlink" href="#build-a-baseline-neural-network-model" title="Permalink to this headline">¶</a></h2>
<div class="section" id="prepare-the-data-for-the-baseline-model">
<h3>Prepare the data for the baseline model<a class="headerlink" href="#prepare-the-data-for-the-baseline-model" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">feature_names</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">papers</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span> <span class="o">-</span> <span class="p">{</span><span class="s2">&quot;paper_id&quot;</span><span class="p">,</span> <span class="s2">&quot;subject&quot;</span><span class="p">}</span>
<span class="n">num_features</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">feature_names</span><span class="p">)</span>
<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">class_idx</span><span class="p">)</span>

<span class="c1"># Create train and test features as a numpy array.</span>
<span class="n">x_train</span> <span class="o">=</span> <span class="n">train_data</span><span class="p">[</span><span class="n">feature_names</span><span class="p">]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
<span class="n">x_test</span> <span class="o">=</span> <span class="n">test_data</span><span class="p">[</span><span class="n">feature_names</span><span class="p">]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
<span class="c1"># Create train and test targets as a numpy array.</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">train_data</span><span class="p">[</span><span class="s2">&quot;subject&quot;</span><span class="p">]</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">test_data</span><span class="p">[</span><span class="s2">&quot;subject&quot;</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/var/folders/68/9tltm6l520v0stj3qjlc5v9w0000gn/T/ipykernel_85979/3641831727.py:6: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.
  x_train = train_data[feature_names].to_numpy()
/var/folders/68/9tltm6l520v0stj3qjlc5v9w0000gn/T/ipykernel_85979/3641831727.py:7: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.
  x_test = test_data[feature_names].to_numpy()
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">num_classes</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>7
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="implement-a-baseline-classifier">
<h3>Implement a baseline classifier<a class="headerlink" href="#implement-a-baseline-classifier" title="Permalink to this headline">¶</a></h3>
<p>We add five FFN blocks with skip connections, so that we generate a baseline model with
roughly the same number of parameters as the GNN models to be built later.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">create_baseline_model</span><span class="p">(</span><span class="n">hidden_units</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="o">=</span><span class="mf">0.2</span><span class="p">):</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">num_features</span><span class="p">,),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;input_features&quot;</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">create_ffn</span><span class="p">(</span><span class="n">hidden_units</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;ffn_block1&quot;</span><span class="p">)(</span><span class="n">inputs</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">block_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span>
        <span class="c1"># Create an FFN block.</span>
        <span class="n">x1</span> <span class="o">=</span> <span class="n">create_ffn</span><span class="p">(</span><span class="n">hidden_units</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;ffn_block</span><span class="si">{</span><span class="n">block_idx</span> <span class="o">+</span> <span class="mi">2</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
        <span class="c1"># Add skip connection.</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Add</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;skip_connection</span><span class="si">{</span><span class="n">block_idx</span> <span class="o">+</span> <span class="mi">2</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)([</span><span class="n">x</span><span class="p">,</span> <span class="n">x1</span><span class="p">])</span>
    <span class="c1"># Compute logits.</span>
    <span class="n">logits</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;logits&quot;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
    <span class="c1"># Create the model.</span>
    <span class="k">return</span> <span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">logits</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;baseline&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">baseline_model</span> <span class="o">=</span> <span class="n">create_baseline_model</span><span class="p">(</span><span class="n">hidden_units</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="p">)</span>
<span class="n">baseline_model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Model: &quot;baseline&quot;
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_features (InputLayer)    [(None, 1433)]       0           []                               
                                                                                                  
 ffn_block1 (Sequential)        (None, 32)           52804       [&#39;input_features[0][0]&#39;]         
                                                                                                  
 ffn_block2 (Sequential)        (None, 32)           2368        [&#39;ffn_block1[0][0]&#39;]             
                                                                                                  
 skip_connection2 (Add)         (None, 32)           0           [&#39;ffn_block1[0][0]&#39;,             
                                                                  &#39;ffn_block2[0][0]&#39;]             
                                                                                                  
 ffn_block3 (Sequential)        (None, 32)           2368        [&#39;skip_connection2[0][0]&#39;]       
                                                                                                  
 skip_connection3 (Add)         (None, 32)           0           [&#39;skip_connection2[0][0]&#39;,       
                                                                  &#39;ffn_block3[0][0]&#39;]             
                                                                                                  
 ffn_block4 (Sequential)        (None, 32)           2368        [&#39;skip_connection3[0][0]&#39;]       
                                                                                                  
 skip_connection4 (Add)         (None, 32)           0           [&#39;skip_connection3[0][0]&#39;,       
                                                                  &#39;ffn_block4[0][0]&#39;]             
                                                                                                  
 ffn_block5 (Sequential)        (None, 32)           2368        [&#39;skip_connection4[0][0]&#39;]       
                                                                                                  
 skip_connection5 (Add)         (None, 32)           0           [&#39;skip_connection4[0][0]&#39;,       
                                                                  &#39;ffn_block5[0][0]&#39;]             
                                                                                                  
 logits (Dense)                 (None, 7)            231         [&#39;skip_connection5[0][0]&#39;]       
                                                                                                  
==================================================================================================
Total params: 62,507
Trainable params: 59,065
Non-trainable params: 3,442
__________________________________________________________________________________________________
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="train-the-baseline-classifier">
<h3>Train the baseline classifier<a class="headerlink" href="#train-the-baseline-classifier" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">history</span> <span class="o">=</span> <span class="n">run_experiment</span><span class="p">(</span><span class="n">baseline_model</span><span class="p">,</span> <span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/300
4/4 [==============================] - 3s 106ms/step - loss: 4.5889 - acc: 0.1514 - val_loss: 1.9021 - val_acc: 0.1703
Epoch 2/300
4/4 [==============================] - 0s 13ms/step - loss: 2.9278 - acc: 0.2547 - val_loss: 1.9420 - val_acc: 0.1509
Epoch 3/300
4/4 [==============================] - 0s 13ms/step - loss: 2.4649 - acc: 0.2484 - val_loss: 1.9246 - val_acc: 0.1509
Epoch 4/300
4/4 [==============================] - 0s 13ms/step - loss: 2.3241 - acc: 0.2578 - val_loss: 1.8946 - val_acc: 0.1509
Epoch 5/300
4/4 [==============================] - 0s 15ms/step - loss: 2.1056 - acc: 0.3132 - val_loss: 1.8766 - val_acc: 0.1898
Epoch 6/300
4/4 [==============================] - 0s 14ms/step - loss: 1.9479 - acc: 0.3267 - val_loss: 1.8698 - val_acc: 0.2457
Epoch 7/300
4/4 [==============================] - 0s 14ms/step - loss: 1.9424 - acc: 0.3152 - val_loss: 1.8675 - val_acc: 0.2555
Epoch 8/300
4/4 [==============================] - 0s 13ms/step - loss: 1.7579 - acc: 0.3319 - val_loss: 1.8660 - val_acc: 0.2482
Epoch 9/300
4/4 [==============================] - 0s 14ms/step - loss: 1.7138 - acc: 0.3622 - val_loss: 1.8551 - val_acc: 0.3382
Epoch 10/300
4/4 [==============================] - 0s 15ms/step - loss: 1.6839 - acc: 0.3925 - val_loss: 1.8370 - val_acc: 0.3577
Epoch 11/300
4/4 [==============================] - 0s 13ms/step - loss: 1.6236 - acc: 0.4008 - val_loss: 1.8106 - val_acc: 0.3455
Epoch 12/300
4/4 [==============================] - 0s 13ms/step - loss: 1.5306 - acc: 0.4384 - val_loss: 1.7820 - val_acc: 0.3382
Epoch 13/300
4/4 [==============================] - 0s 12ms/step - loss: 1.4386 - acc: 0.4843 - val_loss: 1.7547 - val_acc: 0.3406
Epoch 14/300
4/4 [==============================] - 0s 13ms/step - loss: 1.3817 - acc: 0.5104 - val_loss: 1.7096 - val_acc: 0.3455
Epoch 15/300
4/4 [==============================] - 0s 15ms/step - loss: 1.3366 - acc: 0.5042 - val_loss: 1.6659 - val_acc: 0.3771
Epoch 16/300
4/4 [==============================] - 0s 14ms/step - loss: 1.3122 - acc: 0.5084 - val_loss: 1.6272 - val_acc: 0.3504
Epoch 17/300
4/4 [==============================] - 0s 20ms/step - loss: 1.2753 - acc: 0.5282 - val_loss: 1.5787 - val_acc: 0.3650
Epoch 18/300
4/4 [==============================] - 0s 14ms/step - loss: 1.1996 - acc: 0.5616 - val_loss: 1.5106 - val_acc: 0.4161
Epoch 19/300
4/4 [==============================] - 0s 13ms/step - loss: 1.0983 - acc: 0.6013 - val_loss: 1.4588 - val_acc: 0.4428
Epoch 20/300
4/4 [==============================] - 0s 14ms/step - loss: 1.0417 - acc: 0.6326 - val_loss: 1.4257 - val_acc: 0.4501
Epoch 21/300
4/4 [==============================] - 0s 14ms/step - loss: 1.0227 - acc: 0.6315 - val_loss: 1.3811 - val_acc: 0.4647
Epoch 22/300
4/4 [==============================] - 0s 14ms/step - loss: 0.9512 - acc: 0.6670 - val_loss: 1.3589 - val_acc: 0.4696
Epoch 23/300
4/4 [==============================] - 0s 14ms/step - loss: 0.9268 - acc: 0.6743 - val_loss: 1.3319 - val_acc: 0.4842
Epoch 24/300
4/4 [==============================] - 0s 14ms/step - loss: 0.8927 - acc: 0.6931 - val_loss: 1.3267 - val_acc: 0.4915
Epoch 25/300
4/4 [==============================] - 0s 14ms/step - loss: 0.8308 - acc: 0.7098 - val_loss: 1.2861 - val_acc: 0.5255
Epoch 26/300
4/4 [==============================] - 0s 13ms/step - loss: 0.8110 - acc: 0.7234 - val_loss: 1.2331 - val_acc: 0.5474
Epoch 27/300
4/4 [==============================] - 0s 13ms/step - loss: 0.8024 - acc: 0.7098 - val_loss: 1.2009 - val_acc: 0.5572
Epoch 28/300
4/4 [==============================] - 0s 12ms/step - loss: 0.8020 - acc: 0.7244 - val_loss: 1.2097 - val_acc: 0.5547
Epoch 29/300
4/4 [==============================] - 0s 12ms/step - loss: 0.7778 - acc: 0.7192 - val_loss: 1.2731 - val_acc: 0.5328
Epoch 30/300
4/4 [==============================] - 0s 12ms/step - loss: 0.7148 - acc: 0.7578 - val_loss: 1.2623 - val_acc: 0.5304
Epoch 31/300
4/4 [==============================] - 0s 13ms/step - loss: 0.7043 - acc: 0.7443 - val_loss: 1.2044 - val_acc: 0.5620
Epoch 32/300
4/4 [==============================] - 0s 12ms/step - loss: 0.6861 - acc: 0.7474 - val_loss: 1.1604 - val_acc: 0.5888
Epoch 33/300
4/4 [==============================] - 0s 13ms/step - loss: 0.6731 - acc: 0.7683 - val_loss: 1.1446 - val_acc: 0.5912
Epoch 34/300
4/4 [==============================] - 0s 11ms/step - loss: 0.6111 - acc: 0.7818 - val_loss: 1.1463 - val_acc: 0.5912
Epoch 35/300
4/4 [==============================] - 0s 12ms/step - loss: 0.6202 - acc: 0.7891 - val_loss: 1.1656 - val_acc: 0.5693
Epoch 36/300
4/4 [==============================] - 0s 13ms/step - loss: 0.6332 - acc: 0.7944 - val_loss: 1.0853 - val_acc: 0.6107
Epoch 37/300
4/4 [==============================] - 0s 13ms/step - loss: 0.5737 - acc: 0.8111 - val_loss: 1.0072 - val_acc: 0.6618
Epoch 38/300
4/4 [==============================] - 0s 12ms/step - loss: 0.5611 - acc: 0.8111 - val_loss: 1.0213 - val_acc: 0.6423
Epoch 39/300
4/4 [==============================] - 0s 12ms/step - loss: 0.5841 - acc: 0.8017 - val_loss: 1.0163 - val_acc: 0.6594
Epoch 40/300
4/4 [==============================] - 0s 12ms/step - loss: 0.5230 - acc: 0.8236 - val_loss: 0.9921 - val_acc: 0.6813
Epoch 41/300
4/4 [==============================] - 0s 13ms/step - loss: 0.5193 - acc: 0.8173 - val_loss: 0.9543 - val_acc: 0.7007
Epoch 42/300
4/4 [==============================] - 0s 13ms/step - loss: 0.4953 - acc: 0.8361 - val_loss: 0.9370 - val_acc: 0.7129
Epoch 43/300
4/4 [==============================] - 0s 13ms/step - loss: 0.5654 - acc: 0.8121 - val_loss: 0.9604 - val_acc: 0.6837
Epoch 44/300
4/4 [==============================] - 0s 12ms/step - loss: 0.5052 - acc: 0.8225 - val_loss: 0.9632 - val_acc: 0.6740
Epoch 45/300
4/4 [==============================] - 0s 12ms/step - loss: 0.5300 - acc: 0.8225 - val_loss: 0.9447 - val_acc: 0.6837
Epoch 46/300
4/4 [==============================] - 0s 13ms/step - loss: 0.4974 - acc: 0.8215 - val_loss: 0.9252 - val_acc: 0.6813
Epoch 47/300
4/4 [==============================] - 0s 12ms/step - loss: 0.5127 - acc: 0.8236 - val_loss: 0.9085 - val_acc: 0.6959
Epoch 48/300
4/4 [==============================] - 0s 12ms/step - loss: 0.5178 - acc: 0.8299 - val_loss: 0.9081 - val_acc: 0.6959
Epoch 49/300
4/4 [==============================] - 0s 11ms/step - loss: 0.4804 - acc: 0.8278 - val_loss: 0.9081 - val_acc: 0.6959
Epoch 50/300
4/4 [==============================] - 0s 12ms/step - loss: 0.4822 - acc: 0.8278 - val_loss: 0.8827 - val_acc: 0.7153
Epoch 51/300
4/4 [==============================] - 0s 12ms/step - loss: 0.4656 - acc: 0.8351 - val_loss: 0.8797 - val_acc: 0.7080
Epoch 52/300
4/4 [==============================] - 0s 12ms/step - loss: 0.4424 - acc: 0.8528 - val_loss: 0.8869 - val_acc: 0.7105
Epoch 53/300
4/4 [==============================] - 0s 12ms/step - loss: 0.4268 - acc: 0.8601 - val_loss: 0.8852 - val_acc: 0.7032
Epoch 54/300
4/4 [==============================] - 0s 12ms/step - loss: 0.4485 - acc: 0.8539 - val_loss: 0.9395 - val_acc: 0.6618
Epoch 55/300
4/4 [==============================] - 0s 12ms/step - loss: 0.3937 - acc: 0.8633 - val_loss: 0.9439 - val_acc: 0.6569
Epoch 56/300
4/4 [==============================] - 0s 12ms/step - loss: 0.4571 - acc: 0.8455 - val_loss: 0.9002 - val_acc: 0.6886
Epoch 57/300
4/4 [==============================] - 0s 12ms/step - loss: 0.4325 - acc: 0.8570 - val_loss: 0.8447 - val_acc: 0.7153
Epoch 58/300
4/4 [==============================] - 0s 14ms/step - loss: 0.4066 - acc: 0.8685 - val_loss: 0.8395 - val_acc: 0.7153
Epoch 59/300
4/4 [==============================] - 0s 13ms/step - loss: 0.3877 - acc: 0.8706 - val_loss: 0.8277 - val_acc: 0.7202
Epoch 60/300
4/4 [==============================] - 0s 13ms/step - loss: 0.3892 - acc: 0.8643 - val_loss: 0.8177 - val_acc: 0.7251
Epoch 61/300
4/4 [==============================] - 0s 12ms/step - loss: 0.4013 - acc: 0.8716 - val_loss: 0.8319 - val_acc: 0.7105
Epoch 62/300
4/4 [==============================] - 0s 13ms/step - loss: 0.3709 - acc: 0.8831 - val_loss: 0.8560 - val_acc: 0.7056
Epoch 63/300
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>4/4 [==============================] - 0s 12ms/step - loss: 0.4014 - acc: 0.8518 - val_loss: 0.8554 - val_acc: 0.7129
Epoch 64/300
4/4 [==============================] - 0s 12ms/step - loss: 0.4027 - acc: 0.8685 - val_loss: 0.8415 - val_acc: 0.7251
Epoch 65/300
4/4 [==============================] - 0s 12ms/step - loss: 0.4130 - acc: 0.8612 - val_loss: 0.8558 - val_acc: 0.7226
Epoch 66/300
4/4 [==============================] - 0s 13ms/step - loss: 0.4154 - acc: 0.8528 - val_loss: 0.8458 - val_acc: 0.7226
Epoch 67/300
4/4 [==============================] - 0s 12ms/step - loss: 0.4152 - acc: 0.8518 - val_loss: 0.8777 - val_acc: 0.7178
Epoch 68/300
4/4 [==============================] - 0s 12ms/step - loss: 0.3800 - acc: 0.8633 - val_loss: 0.8912 - val_acc: 0.7226
Epoch 69/300
4/4 [==============================] - 0s 13ms/step - loss: 0.4019 - acc: 0.8622 - val_loss: 0.8585 - val_acc: 0.7275
Epoch 70/300
4/4 [==============================] - 0s 12ms/step - loss: 0.3623 - acc: 0.8737 - val_loss: 0.8337 - val_acc: 0.7299
Epoch 71/300
4/4 [==============================] - 0s 13ms/step - loss: 0.3704 - acc: 0.8653 - val_loss: 0.8093 - val_acc: 0.7324
Epoch 72/300
4/4 [==============================] - 0s 12ms/step - loss: 0.3799 - acc: 0.8653 - val_loss: 0.8129 - val_acc: 0.7324
Epoch 73/300
4/4 [==============================] - 0s 12ms/step - loss: 0.3628 - acc: 0.8716 - val_loss: 0.8280 - val_acc: 0.7226
Epoch 74/300
4/4 [==============================] - 0s 12ms/step - loss: 0.4025 - acc: 0.8612 - val_loss: 0.8508 - val_acc: 0.7153
Epoch 75/300
4/4 [==============================] - 0s 15ms/step - loss: 0.3948 - acc: 0.8716 - val_loss: 0.9263 - val_acc: 0.7007
Epoch 76/300
4/4 [==============================] - 0s 13ms/step - loss: 0.4202 - acc: 0.8528 - val_loss: 0.9040 - val_acc: 0.7251
Epoch 77/300
4/4 [==============================] - 0s 12ms/step - loss: 0.4049 - acc: 0.8580 - val_loss: 0.8853 - val_acc: 0.7226
Epoch 78/300
4/4 [==============================] - 0s 13ms/step - loss: 0.3625 - acc: 0.8737 - val_loss: 0.8573 - val_acc: 0.7348
Epoch 79/300
4/4 [==============================] - 0s 12ms/step - loss: 0.3807 - acc: 0.8768 - val_loss: 0.8507 - val_acc: 0.7324
Epoch 80/300
4/4 [==============================] - 0s 13ms/step - loss: 0.3451 - acc: 0.8758 - val_loss: 0.8636 - val_acc: 0.7226
Epoch 81/300
4/4 [==============================] - 0s 14ms/step - loss: 0.3494 - acc: 0.8737 - val_loss: 0.8886 - val_acc: 0.7178
Epoch 82/300
4/4 [==============================] - 0s 14ms/step - loss: 0.3482 - acc: 0.8706 - val_loss: 0.9190 - val_acc: 0.7129
Epoch 83/300
4/4 [==============================] - 0s 13ms/step - loss: 0.3886 - acc: 0.8633 - val_loss: 0.8788 - val_acc: 0.7226
Epoch 84/300
4/4 [==============================] - 0s 13ms/step - loss: 0.3605 - acc: 0.8758 - val_loss: 0.8553 - val_acc: 0.7178
Epoch 85/300
4/4 [==============================] - 0s 14ms/step - loss: 0.3556 - acc: 0.8758 - val_loss: 0.8696 - val_acc: 0.7105
Epoch 86/300
4/4 [==============================] - 0s 15ms/step - loss: 0.3495 - acc: 0.8820 - val_loss: 0.9060 - val_acc: 0.6959
Epoch 87/300
4/4 [==============================] - 0s 16ms/step - loss: 0.3687 - acc: 0.8758 - val_loss: 0.9603 - val_acc: 0.6886
Epoch 88/300
4/4 [==============================] - 0s 12ms/step - loss: 0.3577 - acc: 0.8695 - val_loss: 0.9583 - val_acc: 0.6983
Epoch 89/300
4/4 [==============================] - 0s 15ms/step - loss: 0.3518 - acc: 0.8800 - val_loss: 0.8817 - val_acc: 0.7105
Epoch 90/300
4/4 [==============================] - 0s 18ms/step - loss: 0.3625 - acc: 0.8747 - val_loss: 0.8426 - val_acc: 0.7348
Epoch 91/300
4/4 [==============================] - 0s 15ms/step - loss: 0.3732 - acc: 0.8580 - val_loss: 0.8469 - val_acc: 0.7348
Epoch 92/300
4/4 [==============================] - 0s 13ms/step - loss: 0.4111 - acc: 0.8622 - val_loss: 0.8585 - val_acc: 0.7251
Epoch 93/300
4/4 [==============================] - 0s 15ms/step - loss: 0.3417 - acc: 0.8841 - val_loss: 0.9471 - val_acc: 0.6934
Epoch 94/300
4/4 [==============================] - 0s 22ms/step - loss: 0.3851 - acc: 0.8695 - val_loss: 0.9969 - val_acc: 0.6837
Epoch 95/300
4/4 [==============================] - 0s 12ms/step - loss: 0.3533 - acc: 0.8810 - val_loss: 0.9800 - val_acc: 0.6837
Epoch 96/300
4/4 [==============================] - 0s 17ms/step - loss: 0.3518 - acc: 0.8779 - val_loss: 0.9447 - val_acc: 0.6983
Epoch 97/300
4/4 [==============================] - 0s 16ms/step - loss: 0.3540 - acc: 0.8852 - val_loss: 0.9112 - val_acc: 0.7032
Epoch 98/300
4/4 [==============================] - 0s 14ms/step - loss: 0.3510 - acc: 0.8768 - val_loss: 0.8897 - val_acc: 0.7056
Epoch 99/300
4/4 [==============================] - 0s 12ms/step - loss: 0.3631 - acc: 0.8695 - val_loss: 0.8728 - val_acc: 0.7129
Epoch 100/300
4/4 [==============================] - 0s 12ms/step - loss: 0.3057 - acc: 0.8977 - val_loss: 0.9085 - val_acc: 0.7105
Epoch 101/300
4/4 [==============================] - 0s 12ms/step - loss: 0.3252 - acc: 0.8862 - val_loss: 0.9399 - val_acc: 0.7056
Epoch 102/300
4/4 [==============================] - 0s 12ms/step - loss: 0.3357 - acc: 0.8904 - val_loss: 0.9264 - val_acc: 0.7105
Epoch 103/300
4/4 [==============================] - 0s 13ms/step - loss: 0.3874 - acc: 0.8685 - val_loss: 0.8990 - val_acc: 0.7275
Epoch 104/300
4/4 [==============================] - 0s 13ms/step - loss: 0.3238 - acc: 0.8820 - val_loss: 0.8958 - val_acc: 0.7226
Epoch 105/300
4/4 [==============================] - 0s 14ms/step - loss: 0.3963 - acc: 0.8612 - val_loss: 0.8899 - val_acc: 0.7251
Epoch 106/300
4/4 [==============================] - 0s 12ms/step - loss: 0.3402 - acc: 0.8768 - val_loss: 0.9301 - val_acc: 0.7105
Epoch 107/300
4/4 [==============================] - 0s 12ms/step - loss: 0.3670 - acc: 0.8737 - val_loss: 0.9673 - val_acc: 0.7080
Epoch 108/300
4/4 [==============================] - 0s 12ms/step - loss: 0.3165 - acc: 0.9029 - val_loss: 0.8868 - val_acc: 0.7202
Epoch 109/300
4/4 [==============================] - 0s 12ms/step - loss: 0.3406 - acc: 0.8758 - val_loss: 0.8620 - val_acc: 0.7251
Epoch 110/300
4/4 [==============================] - 0s 12ms/step - loss: 0.3307 - acc: 0.8820 - val_loss: 0.8822 - val_acc: 0.7129
Epoch 111/300
4/4 [==============================] - 0s 12ms/step - loss: 0.3113 - acc: 0.8925 - val_loss: 0.8905 - val_acc: 0.7129
Epoch 112/300
4/4 [==============================] - 0s 13ms/step - loss: 0.3174 - acc: 0.8946 - val_loss: 0.8978 - val_acc: 0.7129
Epoch 113/300
4/4 [==============================] - 0s 15ms/step - loss: 0.3612 - acc: 0.8716 - val_loss: 0.9185 - val_acc: 0.7080
Epoch 114/300
4/4 [==============================] - 0s 13ms/step - loss: 0.3362 - acc: 0.8894 - val_loss: 0.9320 - val_acc: 0.7105
Epoch 115/300
4/4 [==============================] - 0s 12ms/step - loss: 0.3096 - acc: 0.8946 - val_loss: 0.9467 - val_acc: 0.7105
Epoch 116/300
4/4 [==============================] - 0s 12ms/step - loss: 0.2956 - acc: 0.8935 - val_loss: 0.9594 - val_acc: 0.6983
Epoch 117/300
4/4 [==============================] - 0s 13ms/step - loss: 0.3541 - acc: 0.8768 - val_loss: 0.9764 - val_acc: 0.7032
Epoch 118/300
4/4 [==============================] - 0s 12ms/step - loss: 0.2966 - acc: 0.8914 - val_loss: 0.9973 - val_acc: 0.7007
Epoch 119/300
4/4 [==============================] - 0s 12ms/step - loss: 0.3024 - acc: 0.9019 - val_loss: 1.0112 - val_acc: 0.6959
Epoch 120/300
4/4 [==============================] - 0s 12ms/step - loss: 0.3621 - acc: 0.8716 - val_loss: 1.0008 - val_acc: 0.6959
Epoch 121/300
4/4 [==============================] - 0s 13ms/step - loss: 0.3090 - acc: 0.9081 - val_loss: 0.9779 - val_acc: 0.7032
Epoch 122/300
4/4 [==============================] - 0s 14ms/step - loss: 0.3082 - acc: 0.8925 - val_loss: 0.9805 - val_acc: 0.7080
Epoch 123/300
4/4 [==============================] - 0s 15ms/step - loss: 0.3406 - acc: 0.8831 - val_loss: 0.9823 - val_acc: 0.7178
Epoch 124/300
4/4 [==============================] - 0s 16ms/step - loss: 0.3116 - acc: 0.8862 - val_loss: 0.9948 - val_acc: 0.7080
Epoch 125/300
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>4/4 [==============================] - 0s 16ms/step - loss: 0.3094 - acc: 0.8967 - val_loss: 1.0222 - val_acc: 0.7032
Epoch 126/300
4/4 [==============================] - 0s 17ms/step - loss: 0.3423 - acc: 0.8862 - val_loss: 1.0330 - val_acc: 0.6983
Epoch 127/300
4/4 [==============================] - 0s 16ms/step - loss: 0.2945 - acc: 0.8998 - val_loss: 1.0049 - val_acc: 0.7007
Epoch 128/300
4/4 [==============================] - 0s 18ms/step - loss: 0.2955 - acc: 0.8946 - val_loss: 1.0071 - val_acc: 0.7007
</pre></div>
</div>
</div>
</div>
<p>Let’s plot the learning curves.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">display_learning_curves</span><span class="p">(</span><span class="n">history</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/GraphNeuralNetworks_54_0.png" src="../_images/GraphNeuralNetworks_54_0.png" />
</div>
</div>
<p>Now we evaluate the baseline model on the test data split.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">_</span><span class="p">,</span> <span class="n">test_accuracy</span> <span class="o">=</span> <span class="n">baseline_model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Test accuracy: </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">test_accuracy</span> <span class="o">*</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Test accuracy: 72.96%
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="examine-the-baseline-model-predictions">
<h3>Examine the baseline model predictions<a class="headerlink" href="#examine-the-baseline-model-predictions" title="Permalink to this headline">¶</a></h3>
<p>Let’s create new data instances by randomly generating binary word vectors with respect to
the word presence probabilities.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">generate_random_instances</span><span class="p">(</span><span class="n">num_instances</span><span class="p">):</span>
    <span class="n">token_probability</span> <span class="o">=</span> <span class="n">x_train</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">instances</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_instances</span><span class="p">):</span>
        <span class="n">probabilities</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">token_probability</span><span class="p">))</span>
        <span class="n">instance</span> <span class="o">=</span> <span class="p">(</span><span class="n">probabilities</span> <span class="o">&lt;=</span> <span class="n">token_probability</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
        <span class="n">instances</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">instance</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">instances</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">display_class_probabilities</span><span class="p">(</span><span class="n">probabilities</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">instance_idx</span><span class="p">,</span> <span class="n">probs</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">probabilities</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Instance </span><span class="si">{</span><span class="n">instance_idx</span> <span class="o">+</span> <span class="mi">1</span><span class="si">}</span><span class="s2">:&quot;</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">class_idx</span><span class="p">,</span> <span class="n">prob</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">probs</span><span class="p">):</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;- </span><span class="si">{</span><span class="n">class_values</span><span class="p">[</span><span class="n">class_idx</span><span class="p">]</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">prob</span> <span class="o">*</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Now we show the baseline model predictions given these randomly generated instances.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">new_instances</span> <span class="o">=</span> <span class="n">generate_random_instances</span><span class="p">(</span><span class="n">num_classes</span><span class="p">)</span>
<span class="n">logits</span> <span class="o">=</span> <span class="n">baseline_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">new_instances</span><span class="p">)</span>
<span class="n">probabilities</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">activations</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">logits</span><span class="p">))</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="n">display_class_probabilities</span><span class="p">(</span><span class="n">probabilities</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1/1 [==============================] - 0s 196ms/step
Instance 1:
- 0: 3.09%
- 1: 19.7%
- 2: 22.61%
- 3: 3.85%
- 4: 26.74%
- 5: 6.26%
- 6: 17.75%
Instance 2:
- 0: 1.98%
- 1: 8.17%
- 2: 32.91%
- 3: 44.44%
- 4: 5.29%
- 5: 1.51%
- 6: 5.71%
Instance 3:
- 0: 0.09%
- 1: 98.27%
- 2: 1.19%
- 3: 0.09%
- 4: 0.18%
- 5: 0.07%
- 6: 0.1%
Instance 4:
- 0: 0.65%
- 1: 6.01%
- 2: 80.48%
- 3: 1.6%
- 4: 1.97%
- 5: 3.44%
- 6: 5.85%
Instance 5:
- 0: 0.2%
- 1: 0.7%
- 2: 89.49%
- 3: 1.35%
- 4: 1.74%
- 5: 0.47%
- 6: 6.06%
Instance 6:
- 0: 0.24%
- 1: 0.7%
- 2: 97.71%
- 3: 0.85%
- 4: 0.1%
- 5: 0.11%
- 6: 0.28%
Instance 7:
- 0: 0.74%
- 1: 9.94%
- 2: 24.44%
- 3: 1.91%
- 4: 0.89%
- 5: 0.82%
- 6: 61.26%
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="build-a-graph-neural-network-model">
<h2>Build a Graph Neural Network Model<a class="headerlink" href="#build-a-graph-neural-network-model" title="Permalink to this headline">¶</a></h2>
<p><a id='graphinfo'></a></p>
<div class="section" id="prepare-the-data-for-the-graph-model">
<h3>Prepare the data for the graph model<a class="headerlink" href="#prepare-the-data-for-the-graph-model" title="Permalink to this headline">¶</a></h3>
<p>Preparing and loading the graphs data into the model for training is the most challenging
part in GNN models, which is addressed in different ways by the specialised libraries.
In this example, we show a simple approach for preparing and using graph data that is suitable
if your dataset consists of a single graph that fits entirely in memory.</p>
<p>The graph data is represented by the <code class="docutils literal notranslate"><span class="pre">graph_info</span></code> tuple, which consists of the following
three elements:</p>
<ol class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">node_features</span></code>: This is a <code class="docutils literal notranslate"><span class="pre">[num_nodes,</span> <span class="pre">num_features]</span></code> NumPy array that includes the
node features. In this dataset, the nodes are the papers, and the <code class="docutils literal notranslate"><span class="pre">node_features</span></code> are the
word-presence binary vectors of each paper.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">edges</span></code>:  This is a <code class="docutils literal notranslate"><span class="pre">[2,</span> <span class="pre">num_edges]</span></code> NumPy array. The first column contains the id of the source-node and the second column contains the id of the target node of an edge. However, in this application we do not consider directed edges, i.e. it does matter which of the two nodes is the target and the source, respectively.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">edge_weights</span></code> (optional): This is a <code class="docutils literal notranslate"><span class="pre">[num_edges]</span></code> NumPy array that includes the edge weights, which <em>quantify</em>
the relationships between nodes in the graph. In this example, there are no weights for the paper citations.</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create an edges array (sparse adjacency matrix) of shape [2, num_edges].</span>
<span class="n">edges</span> <span class="o">=</span> <span class="n">citations</span><span class="p">[[</span><span class="s2">&quot;source&quot;</span><span class="p">,</span> <span class="s2">&quot;target&quot;</span><span class="p">]]</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">T</span>
<span class="c1"># Create an edge weights array of ones.</span>
<span class="n">edge_weights</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">edges</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="c1"># Create a node features array of shape [num_nodes, num_features].</span>
<span class="n">node_features</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span>
    <span class="n">papers</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s2">&quot;paper_id&quot;</span><span class="p">)[</span><span class="n">feature_names</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">dtypes</span><span class="o">.</span><span class="n">float32</span>
<span class="p">)</span>
<span class="c1"># Create graph info tuple with node_features, edges, and edge_weights.</span>
<span class="n">graph_info</span> <span class="o">=</span> <span class="p">(</span><span class="n">node_features</span><span class="p">,</span> <span class="n">edges</span><span class="p">,</span> <span class="n">edge_weights</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Edges shape:&quot;</span><span class="p">,</span> <span class="n">edges</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Edge-Weight shape:&quot;</span><span class="p">,</span> <span class="n">edge_weights</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Nodes shape:&quot;</span><span class="p">,</span> <span class="n">node_features</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Edges shape: (2, 5429)
Edge-Weight shape: (5429,)
Nodes shape: (2708, 1433)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/var/folders/68/9tltm6l520v0stj3qjlc5v9w0000gn/T/ipykernel_85979/2435838809.py:7: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.
  papers.sort_values(&quot;paper_id&quot;)[feature_names].values, dtype=tf.dtypes.float32
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">edges</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[  21,  905,  906, ..., 2586, 1874, 2707],
       [   0,    0,    0, ..., 1874, 1876, 1897]])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">edge_weights</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;tf.Tensor: shape=(5429,), dtype=float32, numpy=array([1., 1., 1., ..., 1., 1., 1.], dtype=float32)&gt;
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="implement-a-graph-convolution-layer">
<h3>Implement a graph convolution layer<a class="headerlink" href="#implement-a-graph-convolution-layer" title="Permalink to this headline">¶</a></h3>
<p>We implement a graph convolution module as a <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer?version=nightly">Keras Layer</a>.
Our <code class="docutils literal notranslate"><span class="pre">GraphConvLayer</span></code> performs the following steps:</p>
<ol class="simple">
<li><p><strong>Prepare</strong>: The input node representations are processed using a FFN to produce a <em>message</em>. You can simplify
the processing by only applying linear transformation to the representations.</p></li>
<li><p><strong>Aggregate</strong>: The messages of the neighbours of each node are aggregated with
respect to the <code class="docutils literal notranslate"><span class="pre">edge_weights</span></code> using a <em>permutation invariant</em> pooling operation, such as <em>sum</em>, <em>mean</em>, and <em>max</em>,
to prepare a single aggregated message for each node. See, for example, <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/math/unsorted_segment_sum">tf.math.unsorted_segment_sum</a>
APIs used to aggregate neighbour messages.</p></li>
<li><p><strong>Update</strong>: The <code class="docutils literal notranslate"><span class="pre">node_repesentations</span></code> and <code class="docutils literal notranslate"><span class="pre">aggregated_messages</span></code>—both of shape <code class="docutils literal notranslate"><span class="pre">[num_nodes,</span> <span class="pre">representation_dim]</span></code>—
are combined and processed to produce the new state of the node representations (node embeddings).
If <code class="docutils literal notranslate"><span class="pre">combination_type</span></code> is <code class="docutils literal notranslate"><span class="pre">gru</span></code>, the <code class="docutils literal notranslate"><span class="pre">node_repesentations</span></code> and <code class="docutils literal notranslate"><span class="pre">aggregated_messages</span></code> are stacked to create a sequence,
then processed by a GRU layer. Otherwise, the <code class="docutils literal notranslate"><span class="pre">node_repesentations</span></code> and <code class="docutils literal notranslate"><span class="pre">aggregated_messages</span></code> are added
or concatenated, then processed using a FFN.</p></li>
</ol>
<p>The technique implemented use ideas from <a class="reference external" href="https://arxiv.org/abs/1609.02907">Graph Convolutional Networks</a>,
<a class="reference external" href="https://arxiv.org/abs/1706.02216">GraphSage</a>, <a class="reference external" href="https://arxiv.org/abs/1810.00826">Graph Isomorphism Network</a>,
<a class="reference external" href="https://arxiv.org/abs/1902.07153">Simple Graph Networks</a>, and
<a class="reference external" href="https://arxiv.org/abs/1511.05493">Gated Graph Sequence Neural Networks</a>.
Two other key techniques that are not covered are <a class="reference external" href="https://arxiv.org/abs/1710.10903">Graph Attention Networks</a>
and <a class="reference external" href="https://arxiv.org/abs/1704.01212">Message Passing Neural Networks</a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">GraphConvLayer</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">hidden_units</span><span class="p">,</span>
        <span class="n">dropout_rate</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
        <span class="n">aggregation_type</span><span class="o">=</span><span class="s2">&quot;mean&quot;</span><span class="p">,</span>
        <span class="n">combination_type</span><span class="o">=</span><span class="s2">&quot;concat&quot;</span><span class="p">,</span>
        <span class="n">normalize</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="o">*</span><span class="n">args</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">GraphConvLayer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">aggregation_type</span> <span class="o">=</span> <span class="n">aggregation_type</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">combination_type</span> <span class="o">=</span> <span class="n">combination_type</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">normalize</span> <span class="o">=</span> <span class="n">normalize</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">ffn_prepare</span> <span class="o">=</span> <span class="n">create_ffn</span><span class="p">(</span><span class="n">hidden_units</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">combination_type</span> <span class="o">==</span> <span class="s2">&quot;gated&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">update_fn</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span>
                <span class="n">units</span><span class="o">=</span><span class="n">hidden_units</span><span class="p">,</span>
                <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;tanh&quot;</span><span class="p">,</span>
                <span class="n">recurrent_activation</span><span class="o">=</span><span class="s2">&quot;sigmoid&quot;</span><span class="p">,</span>
                <span class="n">dropout</span><span class="o">=</span><span class="n">dropout_rate</span><span class="p">,</span>
                <span class="n">return_state</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">recurrent_dropout</span><span class="o">=</span><span class="n">dropout_rate</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">update_fn</span> <span class="o">=</span> <span class="n">create_ffn</span><span class="p">(</span><span class="n">hidden_units</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">prepare</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">node_repesentations</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="c1"># node_repesentations shape is [num_edges, embedding_dim].</span>
        <span class="n">messages</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ffn_prepare</span><span class="p">(</span><span class="n">node_repesentations</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">weights</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">messages</span> <span class="o">=</span> <span class="n">messages</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">messages</span>

    <span class="k">def</span> <span class="nf">aggregate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">node_indices</span><span class="p">,</span> <span class="n">neighbour_messages</span><span class="p">):</span>
        <span class="c1"># node_indices shape is [num_edges].</span>
        <span class="c1"># neighbour_messages shape: [num_edges, representation_dim].</span>
        <span class="n">num_nodes</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">reduce_max</span><span class="p">(</span><span class="n">node_indices</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">aggregation_type</span> <span class="o">==</span> <span class="s2">&quot;sum&quot;</span><span class="p">:</span>
            <span class="n">aggregated_message</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">unsorted_segment_sum</span><span class="p">(</span>
                <span class="n">neighbour_messages</span><span class="p">,</span> <span class="n">node_indices</span><span class="p">,</span> <span class="n">num_segments</span><span class="o">=</span><span class="n">num_nodes</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">aggregation_type</span> <span class="o">==</span> <span class="s2">&quot;mean&quot;</span><span class="p">:</span>
            <span class="n">aggregated_message</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">unsorted_segment_mean</span><span class="p">(</span>
                <span class="n">neighbour_messages</span><span class="p">,</span> <span class="n">node_indices</span><span class="p">,</span> <span class="n">num_segments</span><span class="o">=</span><span class="n">num_nodes</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">aggregation_type</span> <span class="o">==</span> <span class="s2">&quot;max&quot;</span><span class="p">:</span>
            <span class="n">aggregated_message</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">unsorted_segment_max</span><span class="p">(</span>
                <span class="n">neighbour_messages</span><span class="p">,</span> <span class="n">node_indices</span><span class="p">,</span> <span class="n">num_segments</span><span class="o">=</span><span class="n">num_nodes</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Invalid aggregation type: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">aggregation_type</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">aggregated_message</span>

    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">node_repesentations</span><span class="p">,</span> <span class="n">aggregated_messages</span><span class="p">):</span>
        <span class="c1"># node_repesentations shape is [num_nodes, representation_dim].</span>
        <span class="c1"># aggregated_messages shape is [num_nodes, representation_dim].</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">combination_type</span> <span class="o">==</span> <span class="s2">&quot;gru&quot;</span><span class="p">:</span>
            <span class="c1"># Create a sequence of two elements for the GRU layer.</span>
            <span class="n">h</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">node_repesentations</span><span class="p">,</span> <span class="n">aggregated_messages</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">combination_type</span> <span class="o">==</span> <span class="s2">&quot;concat&quot;</span><span class="p">:</span>
            <span class="c1"># Concatenate the node_repesentations and aggregated_messages.</span>
            <span class="n">h</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">node_repesentations</span><span class="p">,</span> <span class="n">aggregated_messages</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">combination_type</span> <span class="o">==</span> <span class="s2">&quot;add&quot;</span><span class="p">:</span>
            <span class="c1"># Add node_repesentations and aggregated_messages.</span>
            <span class="n">h</span> <span class="o">=</span> <span class="n">node_repesentations</span> <span class="o">+</span> <span class="n">aggregated_messages</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Invalid combination type: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">combination_type</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>

        <span class="c1"># Apply the processing function.</span>
        <span class="n">node_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">update_fn</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">combination_type</span> <span class="o">==</span> <span class="s2">&quot;gru&quot;</span><span class="p">:</span>
            <span class="n">node_embeddings</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">unstack</span><span class="p">(</span><span class="n">node_embeddings</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">normalize</span><span class="p">:</span>
            <span class="n">node_embeddings</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">l2_normalize</span><span class="p">(</span><span class="n">node_embeddings</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">node_embeddings</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Process the inputs to produce the node_embeddings.</span>

<span class="sd">        inputs: a tuple of three elements: node_repesentations, edges, edge_weights.</span>
<span class="sd">        Returns: node_embeddings of shape [num_nodes, representation_dim].</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">node_repesentations</span><span class="p">,</span> <span class="n">edges</span><span class="p">,</span> <span class="n">edge_weights</span> <span class="o">=</span> <span class="n">inputs</span>
        <span class="c1"># Get node_indices (source) and neighbour_indices (target) from edges.</span>
        <span class="n">node_indices</span><span class="p">,</span> <span class="n">neighbour_indices</span> <span class="o">=</span> <span class="n">edges</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">edges</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="c1"># neighbour_repesentations shape is [num_edges, representation_dim].</span>
        <span class="n">neighbour_repesentations</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">node_repesentations</span><span class="p">,</span> <span class="n">neighbour_indices</span><span class="p">)</span>

        <span class="c1"># Prepare the messages of the neighbours.</span>
        <span class="n">neighbour_messages</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">neighbour_repesentations</span><span class="p">,</span> <span class="n">edge_weights</span><span class="p">)</span>
        <span class="c1"># Aggregate the neighbour messages.</span>
        <span class="n">aggregated_messages</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">aggregate</span><span class="p">(</span><span class="n">node_indices</span><span class="p">,</span> <span class="n">neighbour_messages</span><span class="p">)</span>
        <span class="c1"># Update the node embedding with the neighbour messages.</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">node_repesentations</span><span class="p">,</span> <span class="n">aggregated_messages</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="implement-a-graph-neural-network-node-classifier">
<h3>Implement a graph neural network node classifier<a class="headerlink" href="#implement-a-graph-neural-network-node-classifier" title="Permalink to this headline">¶</a></h3>
<p>The GNN classification model follows the <a class="reference external" href="https://arxiv.org/abs/2011.08843">Design Space for Graph Neural Networks</a> approach,
as follows:</p>
<ol class="simple">
<li><p>Apply preprocessing using FFN to the node features to generate initial node representations.</p></li>
<li><p>Apply one or more graph convolutional layer, with skip connections,  to the node representation
to produce node embeddings.</p></li>
<li><p>Apply post-processing using FFN to the node embeddings to generate the final node embeddings.</p></li>
<li><p>Feed the node embeddings in a Softmax layer to predict the node class.</p></li>
</ol>
<figure align="center">
<img src="https://maucher.home.hdm-stuttgart.de/Pics/GNNDesign.png" width="600px" align="center">
<figcaption>
Image Source: <a href="https://arxiv.org/abs/2011.08843">Design Space for Graph Neural Networks</a> 
</figcaption>
</figure>
<p>Each graph convolutional layer added captures information from a further level of neighbours.
However, adding many graph convolutional layer can cause oversmoothing, where the model
produces similar embeddings for all the nodes.</p>
<p>Note that the <code class="docutils literal notranslate"><span class="pre">graph_info</span></code> passed to the constructor of the Keras model, and used as a <em>property</em>
of the Keras model object, rather than input data for training or prediction.
The model will accept a <strong>batch</strong> of <code class="docutils literal notranslate"><span class="pre">node_indices</span></code>, which are used to lookup the
node features and neighbours from the <code class="docutils literal notranslate"><span class="pre">graph_info</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">GNNNodeClassifier</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">graph_info</span><span class="p">,</span>
        <span class="n">num_classes</span><span class="p">,</span>
        <span class="n">hidden_units</span><span class="p">,</span>
        <span class="n">aggregation_type</span><span class="o">=</span><span class="s2">&quot;sum&quot;</span><span class="p">,</span>
        <span class="n">combination_type</span><span class="o">=</span><span class="s2">&quot;concat&quot;</span><span class="p">,</span>
        <span class="n">dropout_rate</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
        <span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="o">*</span><span class="n">args</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">GNNNodeClassifier</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="c1"># Unpack graph_info to three elements: node_features, edges, and edge_weight.</span>
        <span class="n">node_features</span><span class="p">,</span> <span class="n">edges</span><span class="p">,</span> <span class="n">edge_weights</span> <span class="o">=</span> <span class="n">graph_info</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">node_features</span> <span class="o">=</span> <span class="n">node_features</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">edges</span> <span class="o">=</span> <span class="n">edges</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">edge_weights</span> <span class="o">=</span> <span class="n">edge_weights</span>
        <span class="c1"># Set edge_weights to ones if not provided.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">edge_weights</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">edge_weights</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">edges</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="c1"># Scale edge_weights to sum to 1.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">edge_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">edge_weights</span> <span class="o">/</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">edge_weights</span><span class="p">)</span>

        <span class="c1"># Create a process layer.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">preprocess</span> <span class="o">=</span> <span class="n">create_ffn</span><span class="p">(</span><span class="n">hidden_units</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;preprocess&quot;</span><span class="p">)</span>
        <span class="c1"># Create the first GraphConv layer.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">GraphConvLayer</span><span class="p">(</span>
            <span class="n">hidden_units</span><span class="p">,</span>
            <span class="n">dropout_rate</span><span class="p">,</span>
            <span class="n">aggregation_type</span><span class="p">,</span>
            <span class="n">combination_type</span><span class="p">,</span>
            <span class="n">normalize</span><span class="p">,</span>
            <span class="n">name</span><span class="o">=</span><span class="s2">&quot;graph_conv1&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="c1"># Create the second GraphConv layer.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">GraphConvLayer</span><span class="p">(</span>
            <span class="n">hidden_units</span><span class="p">,</span>
            <span class="n">dropout_rate</span><span class="p">,</span>
            <span class="n">aggregation_type</span><span class="p">,</span>
            <span class="n">combination_type</span><span class="p">,</span>
            <span class="n">normalize</span><span class="p">,</span>
            <span class="n">name</span><span class="o">=</span><span class="s2">&quot;graph_conv2&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="c1"># Create a postprocess layer.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">postprocess</span> <span class="o">=</span> <span class="n">create_ffn</span><span class="p">(</span><span class="n">hidden_units</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;postprocess&quot;</span><span class="p">)</span>
        <span class="c1"># Create a compute logits layer.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">compute_logits</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;logits&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_node_indices</span><span class="p">):</span>
        <span class="c1"># Preprocess the node_features to produce node representations.</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">preprocess</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">node_features</span><span class="p">)</span>
        <span class="c1"># Apply the first graph conv layer.</span>
        <span class="n">x1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">((</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">edges</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">edge_weights</span><span class="p">))</span>
        <span class="c1"># Skip connection.</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x1</span> <span class="o">+</span> <span class="n">x</span>
        <span class="c1"># Apply the second graph conv layer.</span>
        <span class="n">x2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">((</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">edges</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">edge_weights</span><span class="p">))</span>
        <span class="c1"># Skip connection.</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x2</span> <span class="o">+</span> <span class="n">x</span>
        <span class="c1"># Postprocess node embedding.</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">postprocess</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="c1"># Fetch node embeddings for the input node_indices.</span>
        <span class="n">node_embeddings</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">input_node_indices</span><span class="p">))</span>
        <span class="c1"># Compute logits</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_logits</span><span class="p">(</span><span class="n">node_embeddings</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s test instantiating and calling the GNN model.
Notice that if you provide <code class="docutils literal notranslate"><span class="pre">N</span></code> node indices, the output will be a tensor of shape <code class="docutils literal notranslate"><span class="pre">[N,</span> <span class="pre">num_classes]</span></code>,
regardless of the size of the graph.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">create_ffn</span><span class="p">(</span><span class="n">hidden_units</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">fnn_layers</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">units</span> <span class="ow">in</span> <span class="n">hidden_units</span><span class="p">:</span>
        <span class="n">fnn_layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">())</span>
        <span class="n">fnn_layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_rate</span><span class="p">))</span>
        <span class="n">fnn_layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">units</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">gelu</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">fnn_layers</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">gnn_model</span> <span class="o">=</span> <span class="n">GNNNodeClassifier</span><span class="p">(</span>
    <span class="n">graph_info</span><span class="o">=</span><span class="n">graph_info</span><span class="p">,</span>
    <span class="n">num_classes</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span>
    <span class="n">hidden_units</span><span class="o">=</span><span class="n">hidden_units</span><span class="p">,</span>
    <span class="n">dropout_rate</span><span class="o">=</span><span class="n">dropout_rate</span><span class="p">,</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;gnn_model&quot;</span><span class="p">,</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;GNN output shape:&quot;</span><span class="p">,</span> <span class="n">gnn_model</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">]))</span>

<span class="n">gnn_model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>GNN output shape: tf.Tensor(
[[ 0.03601404 -0.01548645  0.00206448  0.00862695 -0.09617302 -0.06045327
  -0.04300931]
 [ 0.079326   -0.10742673 -0.00494084 -0.02116663  0.13599855 -0.06459352
  -0.08425424]
 [ 0.02355492  0.00252466 -0.01546108  0.04737538 -0.1041384   0.00663401
   0.00331598]], shape=(3, 7), dtype=float32)
Model: &quot;gnn_model&quot;
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 preprocess (Sequential)     (2708, 32)                52804     
                                                                 
 graph_conv1 (GraphConvLayer  multiple                 5888      
 )                                                               
                                                                 
 graph_conv2 (GraphConvLayer  multiple                 5888      
 )                                                               
                                                                 
 postprocess (Sequential)    (2708, 32)                2368      
                                                                 
 logits (Dense)              multiple                  231       
                                                                 
=================================================================
Total params: 67,179
Trainable params: 63,481
Non-trainable params: 3,698
_________________________________________________________________
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="train-the-gnn-model">
<h3>Train the GNN model<a class="headerlink" href="#train-the-gnn-model" title="Permalink to this headline">¶</a></h3>
<p>Note that we use the standard <em>supervised</em> cross-entropy loss to train the model.
However, we can add another <em>self-supervised</em> loss term for the generated node embeddings
that makes sure that neighbouring nodes in graph have similar representations, while faraway
nodes have dissimilar representations.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x_train</span> <span class="o">=</span> <span class="n">train_data</span><span class="o">.</span><span class="n">paper_id</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
<span class="c1">#print(x_train.shape)</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">run_experiment</span><span class="p">(</span><span class="n">gnn_model</span><span class="p">,</span> <span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s plot the learning curves</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">display_learning_curves</span><span class="p">(</span><span class="n">history</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Now we evaluate the GNN model on the test data split.
The results may vary depending on the training sample, however the GNN model always outperforms
the baseline model in terms of the test accuracy.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x_test</span> <span class="o">=</span> <span class="n">test_data</span><span class="o">.</span><span class="n">paper_id</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
<span class="n">_</span><span class="p">,</span> <span class="n">test_accuracy</span> <span class="o">=</span> <span class="n">gnn_model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Test accuracy: </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">test_accuracy</span> <span class="o">*</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="examine-the-gnn-model-predictions">
<h3>Examine the GNN model predictions<a class="headerlink" href="#examine-the-gnn-model-predictions" title="Permalink to this headline">¶</a></h3>
<p>Let’s add the new instances as nodes to the <code class="docutils literal notranslate"><span class="pre">node_features</span></code>, and generate links
(citations) to existing nodes.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># First we add the N new_instances as nodes to the graph</span>
<span class="c1"># by appending the new_instance to node_features.</span>
<span class="n">num_nodes</span> <span class="o">=</span> <span class="n">node_features</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">new_node_features</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">node_features</span><span class="p">,</span> <span class="n">new_instances</span><span class="p">])</span>
<span class="c1"># Second we add the M edges (citations) from each new node to a set</span>
<span class="c1"># of existing nodes in a particular subject</span>
<span class="n">new_node_indices</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="n">num_nodes</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_classes</span><span class="p">)]</span>
<span class="n">new_citations</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">subject_idx</span><span class="p">,</span> <span class="n">group</span> <span class="ow">in</span> <span class="n">papers</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s2">&quot;subject&quot;</span><span class="p">):</span>
    <span class="n">subject_papers</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">group</span><span class="o">.</span><span class="n">paper_id</span><span class="p">)</span>
    <span class="c1"># Select random x papers specific subject.</span>
    <span class="n">selected_paper_indices1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">subject_papers</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
    <span class="c1"># Select random y papers from any subject (where y &lt; x).</span>
    <span class="n">selected_paper_indices2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">papers</span><span class="o">.</span><span class="n">paper_id</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>
    <span class="c1"># Merge the selected paper indices.</span>
    <span class="n">selected_paper_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span>
        <span class="p">[</span><span class="n">selected_paper_indices1</span><span class="p">,</span> <span class="n">selected_paper_indices2</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span>
    <span class="p">)</span>
    <span class="c1"># Create edges between a citing paper idx and the selected cited papers.</span>
    <span class="n">citing_paper_indx</span> <span class="o">=</span> <span class="n">new_node_indices</span><span class="p">[</span><span class="n">subject_idx</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">cited_paper_idx</span> <span class="ow">in</span> <span class="n">selected_paper_indices</span><span class="p">:</span>
        <span class="n">new_citations</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">citing_paper_indx</span><span class="p">,</span> <span class="n">cited_paper_idx</span><span class="p">])</span>

<span class="n">new_citations</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">new_citations</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
<span class="n">new_edges</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">edges</span><span class="p">,</span> <span class="n">new_citations</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Now let’s update the <code class="docutils literal notranslate"><span class="pre">node_features</span></code> and the <code class="docutils literal notranslate"><span class="pre">edges</span></code> in the GNN model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Original node_features shape:&quot;</span><span class="p">,</span> <span class="n">gnn_model</span><span class="o">.</span><span class="n">node_features</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Original edges shape:&quot;</span><span class="p">,</span> <span class="n">gnn_model</span><span class="o">.</span><span class="n">edges</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">gnn_model</span><span class="o">.</span><span class="n">node_features</span> <span class="o">=</span> <span class="n">new_node_features</span>
<span class="n">gnn_model</span><span class="o">.</span><span class="n">edges</span> <span class="o">=</span> <span class="n">new_edges</span>
<span class="n">gnn_model</span><span class="o">.</span><span class="n">edge_weights</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">new_edges</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;New node_features shape:&quot;</span><span class="p">,</span> <span class="n">gnn_model</span><span class="o">.</span><span class="n">node_features</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;New edges shape:&quot;</span><span class="p">,</span> <span class="n">gnn_model</span><span class="o">.</span><span class="n">edges</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="n">logits</span> <span class="o">=</span> <span class="n">gnn_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">new_node_indices</span><span class="p">))</span>
<span class="n">probabilities</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">activations</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">logits</span><span class="p">))</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="n">display_class_probabilities</span><span class="p">(</span><span class="n">probabilities</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Notice that the probabilities of the expected subjects
(to which several citations are added) are higher compared to the baseline model.</p>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./neuralnetworks"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
        <div class='prev-next-bottom'>
            
    <a class='left-prev' id="prev-link" href="../text/02TextClassification.html" title="previous page">Text classification with CNNs and LSTMs</a>
    <a class='right-next' id="next-link" href="../transformer/attention.html" title="next page">Sequence-To-Sequence, Attention, Transformer</a>

        </div>
        
        </div>
    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Prof. Dr. Johannes Maucher<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
  </body>
</html>